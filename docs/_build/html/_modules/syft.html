

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="python" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="python" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>syft package &mdash; PySyft 0.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> PySyft
          

          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">syft package</a><ul>
<li><a class="reference internal" href="#subpackages">Subpackages</a></li>
<li><a class="reference internal" href="#module-syft">Module contents</a></li>
</ul>
</li>
</ul>
</div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PySyft</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>syft package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/_modules/syft.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="syft-package">
<h1>syft package<a class="headerlink" href="#syft-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="syft.core.html">syft.core package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="syft.core.html#subpackages">Subpackages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="syft.core.frameworks.html">syft.core.frameworks package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="syft.core.frameworks.html#subpackages">Subpackages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="syft.core.frameworks.torch.html">syft.core.frameworks.torch package</a><ul>
<li class="toctree-l6"><a class="reference internal" href="syft.core.frameworks.torch.html#submodules">Submodules</a></li>
<li class="toctree-l6"><a class="reference internal" href="syft.core.frameworks.torch.html#module-syft.core.frameworks.torch.hook">syft.core.frameworks.torch.hook module</a></li>
<li class="toctree-l6"><a class="reference internal" href="syft.core.frameworks.torch.html#module-syft.core.frameworks.torch.tensor">syft.core.frameworks.torch.tensor module</a></li>
<li class="toctree-l6"><a class="reference internal" href="syft.core.frameworks.torch.html#module-syft.core.frameworks.torch">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="syft.core.frameworks.html#module-syft.core.frameworks">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="syft.core.hooks.html">syft.core.hooks package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="syft.core.hooks.html#subpackages">Subpackages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="syft.core.hooks.torch.html">syft.core.hooks.torch package</a><ul>
<li class="toctree-l6"><a class="reference internal" href="syft.core.hooks.torch.html#submodules">Submodules</a></li>
<li class="toctree-l6"><a class="reference internal" href="syft.core.hooks.torch.html#module-syft.core.hooks.torch.guard">syft.core.hooks.torch.guard module</a></li>
<li class="toctree-l6"><a class="reference internal" href="syft.core.hooks.torch.html#module-syft.core.hooks.torch.hook">syft.core.hooks.torch.hook module</a></li>
<li class="toctree-l6"><a class="reference internal" href="syft.core.hooks.torch.html#module-syft.core.hooks.torch.tensor">syft.core.hooks.torch.tensor module</a></li>
<li class="toctree-l6"><a class="reference internal" href="syft.core.hooks.torch.html#module-contents">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="syft.core.hooks.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="syft.core.hooks.html#module-syft.core.hooks.base">syft.core.hooks.base module</a></li>
<li class="toctree-l4"><a class="reference internal" href="syft.core.hooks.html#module-syft.core.hooks.keras">syft.core.hooks.keras module</a></li>
<li class="toctree-l4"><a class="reference internal" href="syft.core.hooks.html#module-syft.core.hooks.tensorflow">syft.core.hooks.tensorflow module</a></li>
<li class="toctree-l4"><a class="reference internal" href="syft.core.hooks.html#module-syft.core.hooks">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="syft.core.workers.html">syft.core.workers package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="syft.core.workers.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="syft.core.workers.html#module-syft.core.workers.base">syft.core.workers.base module</a></li>
<li class="toctree-l4"><a class="reference internal" href="syft.core.workers.html#module-syft.core.workers.socket">syft.core.workers.socket module</a></li>
<li class="toctree-l4"><a class="reference internal" href="syft.core.workers.html#module-syft.core.workers.virtual">syft.core.workers.virtual module</a></li>
<li class="toctree-l4"><a class="reference internal" href="syft.core.workers.html#module-syft.core.workers">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="syft.core.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="syft.core.html#module-syft.core.utils">syft.core.utils module</a></li>
<li class="toctree-l2"><a class="reference internal" href="syft.core.html#module-syft.core">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="syft.mpc.html">syft.mpc package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="syft.mpc.html#subpackages">Subpackages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="syft.mpc.interface.html">syft.mpc.interface package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="syft.mpc.interface.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="syft.mpc.interface.html#module-syft.mpc.interface.base_interface">syft.mpc.interface.base_interface module</a></li>
<li class="toctree-l4"><a class="reference internal" href="syft.mpc.interface.html#module-syft.mpc.interface.distributed_interface">syft.mpc.interface.distributed_interface module</a></li>
<li class="toctree-l4"><a class="reference internal" href="syft.mpc.interface.html#module-syft.mpc.interface.grid_client_interface">syft.mpc.interface.grid_client_interface module</a></li>
<li class="toctree-l4"><a class="reference internal" href="syft.mpc.interface.html#module-syft.mpc.interface.grid_worker_interface">syft.mpc.interface.grid_worker_interface module</a></li>
<li class="toctree-l4"><a class="reference internal" href="syft.mpc.interface.html#module-syft.mpc.interface">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="syft.mpc.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="syft.mpc.html#module-syft.mpc.shared_variable">syft.mpc.shared_variable module</a></li>
<li class="toctree-l2"><a class="reference internal" href="syft.mpc.html#module-syft.mpc.spdz">syft.mpc.spdz module</a></li>
<li class="toctree-l2"><a class="reference internal" href="syft.mpc.html#module-syft.mpc">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="module-syft">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-syft" title="Permalink to this headline">¶</a></h2>
<p>The torch package contains data structures for multi-dimensional
tensors and mathematical operations over these are defined.
Additionally, it provides many utilities for efficient serializing of
Tensors and arbitrary types, and other useful utilities.</p>
<p>It has a CUDA counterpart, that enables you to run your tensor computations
on an NVIDIA GPU with compute capability &gt;= 3.0.</p>
<dl class="function">
<dt id="syft.typename">
<code class="descclassname">syft.</code><code class="descname">typename</code><span class="sig-paren">(</span><em>o</em><span class="sig-paren">)</span><a class="reference internal" href="torch.html#typename"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.typename" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="syft.is_tensor">
<code class="descclassname">syft.</code><code class="descname">is_tensor</code><span class="sig-paren">(</span><em>obj</em><span class="sig-paren">)</span><a class="reference internal" href="torch.html#is_tensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.is_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns True if <cite>obj</cite> is a pytorch tensor.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>obj (Object): Object to test</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="syft.is_storage">
<code class="descclassname">syft.</code><code class="descname">is_storage</code><span class="sig-paren">(</span><em>obj</em><span class="sig-paren">)</span><a class="reference internal" href="torch.html#is_storage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.is_storage" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns True if <cite>obj</cite> is a pytorch storage object.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>obj (Object): Object to test</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="syft.set_default_tensor_type">
<code class="descclassname">syft.</code><code class="descname">set_default_tensor_type</code><span class="sig-paren">(</span><em>t</em><span class="sig-paren">)</span><a class="reference internal" href="torch.html#set_default_tensor_type"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.set_default_tensor_type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="syft.set_rng_state">
<code class="descclassname">syft.</code><code class="descname">set_rng_state</code><span class="sig-paren">(</span><em>new_state</em><span class="sig-paren">)</span><a class="reference internal" href="torch/random.html#set_rng_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.set_rng_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the random number generator state.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>new_state (torch.ByteTensor): The desired state</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="syft.get_rng_state">
<code class="descclassname">syft.</code><code class="descname">get_rng_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="torch/random.html#get_rng_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.get_rng_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the random number generator state as a ByteTensor.</p>
</dd></dl>

<dl class="function">
<dt id="syft.manual_seed">
<code class="descclassname">syft.</code><code class="descname">manual_seed</code><span class="sig-paren">(</span><em>seed</em><span class="sig-paren">)</span><a class="reference internal" href="torch/random.html#manual_seed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.manual_seed" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the seed for generating random numbers. And returns a
<cite>torch._C.Generator</cite> object.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>seed (int or long): The desired seed.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="syft.initial_seed">
<code class="descclassname">syft.</code><code class="descname">initial_seed</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="torch/random.html#initial_seed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.initial_seed" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the initial seed for generating random numbers as a
python <cite>long</cite>.</p>
</dd></dl>

<dl class="function">
<dt id="syft.save">
<code class="descclassname">syft.</code><code class="descname">save</code><span class="sig-paren">(</span><em>obj</em>, <em>f</em>, <em>pickle_module=&lt;module 'pickle' from '/Users/atrask/anaconda/lib/python3.6/pickle.py'&gt;</em>, <em>pickle_protocol=2</em><span class="sig-paren">)</span><a class="reference internal" href="torch/serialization.html#save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves an object to a disk file.</p>
<p>See also: <span class="xref std std-ref">recommend-saving-models</span></p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">obj: saved object
f: a file-like object (has to implement fileno that returns a file descriptor)</p>
<blockquote>
<div>or a string containing a file name</div></blockquote>
<p class="last">pickle_module: module used for pickling metadata and objects
pickle_protocol: can be specified to override the default protocol</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="syft.load">
<code class="descclassname">syft.</code><code class="descname">load</code><span class="sig-paren">(</span><em>f</em>, <em>map_location=None</em>, <em>pickle_module=&lt;module 'pickle' from '/Users/atrask/anaconda/lib/python3.6/pickle.py'&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="torch/serialization.html#load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads an object saved with <code class="xref py py-func docutils literal"><span class="pre">torch.save()</span></code> from a file.</p>
<p>torch.load uses Python&#8217;s unpickling facilities but treats storages,
which underlie tensors, specially. They are first deserialized on the
CPU and are then moved to the device they were saved from. If this fails
(e.g. because the run time system doesn&#8217;t have certain devices), an exception
is raised. However, storages can be dynamically remapped to an alternative
set of devices using the map_location argument.</p>
<p>If map_location is a callable, it will be called once for each serialized
storage with two arguments: storage and location. The storage argument
will be the initial deserialization of the storage, residing on the CPU.
Each serialized storage has a location tag associated with it which
identifies the device it was saved from, and this tag is the second
argument passed to map_location. The builtin location tags are &#8216;cpu&#8217; for
CPU tensors and &#8216;cuda:device_id&#8217; (e.g. &#8216;cuda:2&#8217;) for CUDA tensors.
map_location should return either None or a storage. If map_location returns
a storage, it will be used as the final deserialized object, already moved to
the right device. Otherwise, torch.load will fall back to the default behavior,
as if map_location wasn&#8217;t specified.</p>
<p>If map_location is a dict, it will be used to remap location tags
appearing in the file (keys), to ones that specify where to put the
storages (values).</p>
<p>User extensions can register their own location tags and tagging and
deserialization methods using register_package.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first last docutils">
<dt>f: a file-like object (has to implement fileno that returns a file</dt>
<dd>descriptor, and must implement seek), or a string containing a file
name</dd>
<dt>map_location: a function or a dict specifying how to remap storage</dt>
<dd>locations</dd>
<dt>pickle_module: module used for unpickling metadata and objects (has to</dt>
<dd>match the pickle_module used to serialize file)</dd>
</dl>
</dd>
<dt>Example:</dt>
<dd><div class="first last highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;tensors.pt&#39;</span><span class="p">)</span>
<span class="go"># Load all tensors onto the CPU</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;tensors.pt&#39;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="k">lambda</span> <span class="n">storage</span><span class="p">,</span> <span class="n">loc</span><span class="p">:</span> <span class="n">storage</span><span class="p">)</span>
<span class="go"># Load all tensors onto GPU 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;tensors.pt&#39;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="k">lambda</span> <span class="n">storage</span><span class="p">,</span> <span class="n">loc</span><span class="p">:</span> <span class="n">storage</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="go"># Map tensors from GPU 1 to GPU 0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;tensors.pt&#39;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">:</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">})</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="syft.set_printoptions">
<code class="descclassname">syft.</code><code class="descname">set_printoptions</code><span class="sig-paren">(</span><em>precision=None</em>, <em>threshold=None</em>, <em>edgeitems=None</em>, <em>linewidth=None</em>, <em>profile=None</em><span class="sig-paren">)</span><a class="reference internal" href="torch/_tensor_str.html#set_printoptions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.set_printoptions" title="Permalink to this definition">¶</a></dt>
<dd><p>Set options for printing. Items shamelessly taken from Numpy</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first last docutils">
<dt>precision: Number of digits of precision for floating point output</dt>
<dd>(default 8).</dd>
<dt>threshold: Total number of array elements which trigger summarization</dt>
<dd>rather than full repr (default 1000).</dd>
<dt>edgeitems: Number of array items in summary at beginning and end of</dt>
<dd>each dimension (default 3).</dd>
<dt>linewidth: The number of characters per line for the purpose of</dt>
<dd>inserting line breaks (default 80). Thresholded matricies will
ignore this parameter.</dd>
<dt>profile: Sane defaults for pretty printing. Can override with any of</dt>
<dd>the above options. (default, short, full)</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="syft.chunk">
<code class="descclassname">syft.</code><code class="descname">chunk</code><span class="sig-paren">(</span><em>tensor</em>, <em>chunks</em>, <em>dim=0</em><span class="sig-paren">)</span><a class="reference internal" href="torch/functional.html#chunk"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.chunk" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits a tensor into a number of chunks along a given dimension.</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>tensor (Tensor): tensor to split.
chunks (int): number of chunks to return.
dim (int): dimension along which to split the tensor.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="syft.split">
<code class="descclassname">syft.</code><code class="descname">split</code><span class="sig-paren">(</span><em>tensor</em>, <em>split_size</em>, <em>dim=0</em><span class="sig-paren">)</span><a class="reference internal" href="torch/functional.html#split"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits the tensor into equally sized chunks (if possible).</p>
<p>Last chunk will be smaller if the tensor size along a given dimension
is not divisible by <code class="docutils literal"><span class="pre">split_size</span></code>.</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>tensor (Tensor): tensor to split.
split_size (int): size of a single chunk.
dim (int): dimension along which to split the tensor.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="syft.stack">
<code class="descclassname">syft.</code><code class="descname">stack</code><span class="sig-paren">(</span><em>sequence</em>, <em>dim=0</em>, <em>out=None</em><span class="sig-paren">)</span><a class="reference internal" href="torch/functional.html#stack"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.stack" title="Permalink to this definition">¶</a></dt>
<dd><p>Concatenates sequence of tensors along a new dimension.</p>
<p>All tensors need to be of the same size.</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd><p class="first">sequence (Sequence): sequence of tensors to concatenate.
dim (int): dimension to insert. Has to be between 0 and the number</p>
<blockquote class="last">
<div>of dimensions of concatenated tensors (inclusive).</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="syft.matmul">
<code class="descclassname">syft.</code><code class="descname">matmul</code><span class="sig-paren">(</span><em>tensor1</em>, <em>tensor2</em>, <em>out=None</em><span class="sig-paren">)</span><a class="reference internal" href="torch/functional.html#matmul"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.matmul" title="Permalink to this definition">¶</a></dt>
<dd><p>Matrix product of two tensors.</p>
<p>The behavior depends on the dimensionality of the tensors as follows:</p>
<ul class="simple">
<li>If both tensors are 1-dimensional, the dot product (scalar) is returned.</li>
<li>If both arguments are 2-dimensional, the matrix-matrix product is returned.</li>
<li>If the first argument is 1-dimensional and the second argument is 2-dimensional,
a 1 is prepended to its dimension for the purpose of the matrix multiply.
After the matrix multiply, the prepended dimension is removed.</li>
<li>If the first argument is 2-dimensional and the second argument is 1-dimensional,
the matrix-vector product is returned.</li>
<li>If both arguments are at least 1-dimensional and at least one argument is
N-dimensional (where N &gt; 2), then a batched matrix multiply is returned.  If the first
argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the
batched matrix multiply and removed after.  If the second argument is 1-dimensional, a
1 is appended to its dimension for the purpose of the batched matrix multiple and removed after.
The non-matrix (i.e. batch) dimensions are <span class="xref std std-ref">broadcasted</span> (and thus
must be broadcastable).  For example, if <code class="xref py py-attr docutils literal"><span class="pre">tensor1</span></code> is a <cite>j x 1 x n x m</cite> Tensor
and <code class="xref py py-attr docutils literal"><span class="pre">tensor2</span></code> is a <cite>k x m x p</cite> Tensor, <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will be an <cite>j x k x n x p</cite> Tensor.</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The 1-dimensional dot product version of this function does not support an <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> parameter.</p>
</div>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>tensor1 (Tensor): First tensor to be multiplied
tensor2 (Tensor): Second tensor to be multiplied
out (Tensor, optional): Output tensor</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="syft.DoubleStorage">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">DoubleStorage</code><a class="reference internal" href="torch.html#DoubleStorage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.DoubleStorage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">torch._C.DoubleStorageBase</span></code>, <code class="xref py py-class docutils literal"><span class="pre">torch.storage._StorageBase</span></code></p>
</dd></dl>

<dl class="class">
<dt id="syft.FloatStorage">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">FloatStorage</code><a class="reference internal" href="torch.html#FloatStorage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.FloatStorage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">torch._C.FloatStorageBase</span></code>, <code class="xref py py-class docutils literal"><span class="pre">torch.storage._StorageBase</span></code></p>
</dd></dl>

<dl class="class">
<dt id="syft.LongStorage">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">LongStorage</code><a class="reference internal" href="torch.html#LongStorage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.LongStorage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">torch._C.LongStorageBase</span></code>, <code class="xref py py-class docutils literal"><span class="pre">torch.storage._StorageBase</span></code></p>
</dd></dl>

<dl class="class">
<dt id="syft.IntStorage">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">IntStorage</code><a class="reference internal" href="torch.html#IntStorage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.IntStorage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">torch._C.IntStorageBase</span></code>, <code class="xref py py-class docutils literal"><span class="pre">torch.storage._StorageBase</span></code></p>
</dd></dl>

<dl class="class">
<dt id="syft.ShortStorage">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">ShortStorage</code><a class="reference internal" href="torch.html#ShortStorage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.ShortStorage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">torch._C.ShortStorageBase</span></code>, <code class="xref py py-class docutils literal"><span class="pre">torch.storage._StorageBase</span></code></p>
</dd></dl>

<dl class="class">
<dt id="syft.CharStorage">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">CharStorage</code><a class="reference internal" href="torch.html#CharStorage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.CharStorage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">torch._C.CharStorageBase</span></code>, <code class="xref py py-class docutils literal"><span class="pre">torch.storage._StorageBase</span></code></p>
</dd></dl>

<dl class="class">
<dt id="syft.ByteStorage">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">ByteStorage</code><a class="reference internal" href="torch.html#ByteStorage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.ByteStorage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">torch._C.ByteStorageBase</span></code>, <code class="xref py py-class docutils literal"><span class="pre">torch.storage._StorageBase</span></code></p>
</dd></dl>

<dl class="class">
<dt id="syft.DoubleTensor">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">DoubleTensor</code><a class="reference internal" href="torch.html#DoubleTensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.DoubleTensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">torch._C.DoubleTensorBase</span></code>, <code class="xref py py-class docutils literal"><span class="pre">torch.tensor._TensorBase</span></code></p>
<dl class="method">
<dt id="syft.DoubleTensor.is_signed">
<code class="descname">is_signed</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="torch.html#DoubleTensor.is_signed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.DoubleTensor.is_signed" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="syft.DoubleTensor.storage_type">
<em class="property">classmethod </em><code class="descname">storage_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="torch.html#DoubleTensor.storage_type"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.DoubleTensor.storage_type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="syft.FloatTensor">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">FloatTensor</code><a class="reference internal" href="torch.html#FloatTensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.FloatTensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">torch._C.FloatTensorBase</span></code>, <code class="xref py py-class docutils literal"><span class="pre">torch.tensor._TensorBase</span></code></p>
<dl class="method">
<dt id="syft.FloatTensor.is_signed">
<code class="descname">is_signed</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="torch.html#FloatTensor.is_signed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.FloatTensor.is_signed" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="syft.FloatTensor.storage_type">
<em class="property">classmethod </em><code class="descname">storage_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="torch.html#FloatTensor.storage_type"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.FloatTensor.storage_type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="syft.LongTensor">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">LongTensor</code><a class="reference internal" href="torch.html#LongTensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.LongTensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">torch._C.LongTensorBase</span></code>, <code class="xref py py-class docutils literal"><span class="pre">torch.tensor._TensorBase</span></code></p>
<dl class="method">
<dt id="syft.LongTensor.is_signed">
<code class="descname">is_signed</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="torch.html#LongTensor.is_signed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.LongTensor.is_signed" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="syft.LongTensor.storage_type">
<em class="property">classmethod </em><code class="descname">storage_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="torch.html#LongTensor.storage_type"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.LongTensor.storage_type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="syft.IntTensor">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">IntTensor</code><a class="reference internal" href="torch.html#IntTensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.IntTensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">torch._C.IntTensorBase</span></code>, <code class="xref py py-class docutils literal"><span class="pre">torch.tensor._TensorBase</span></code></p>
<dl class="method">
<dt id="syft.IntTensor.is_signed">
<code class="descname">is_signed</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="torch.html#IntTensor.is_signed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.IntTensor.is_signed" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="syft.IntTensor.storage_type">
<em class="property">classmethod </em><code class="descname">storage_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="torch.html#IntTensor.storage_type"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.IntTensor.storage_type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="syft.ShortTensor">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">ShortTensor</code><a class="reference internal" href="torch.html#ShortTensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.ShortTensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">torch._C.ShortTensorBase</span></code>, <code class="xref py py-class docutils literal"><span class="pre">torch.tensor._TensorBase</span></code></p>
<dl class="method">
<dt id="syft.ShortTensor.is_signed">
<code class="descname">is_signed</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="torch.html#ShortTensor.is_signed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.ShortTensor.is_signed" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="syft.ShortTensor.storage_type">
<em class="property">classmethod </em><code class="descname">storage_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="torch.html#ShortTensor.storage_type"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.ShortTensor.storage_type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="syft.CharTensor">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">CharTensor</code><a class="reference internal" href="torch.html#CharTensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.CharTensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">torch._C.CharTensorBase</span></code>, <code class="xref py py-class docutils literal"><span class="pre">torch.tensor._TensorBase</span></code></p>
<dl class="method">
<dt id="syft.CharTensor.is_signed">
<code class="descname">is_signed</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="torch.html#CharTensor.is_signed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.CharTensor.is_signed" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="syft.CharTensor.storage_type">
<em class="property">classmethod </em><code class="descname">storage_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="torch.html#CharTensor.storage_type"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.CharTensor.storage_type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="syft.ByteTensor">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">ByteTensor</code><a class="reference internal" href="torch.html#ByteTensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.ByteTensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">torch._C.ByteTensorBase</span></code>, <code class="xref py py-class docutils literal"><span class="pre">torch.tensor._TensorBase</span></code></p>
<dl class="method">
<dt id="syft.ByteTensor.is_signed">
<code class="descname">is_signed</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="torch.html#ByteTensor.is_signed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.ByteTensor.is_signed" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="syft.ByteTensor.storage_type">
<em class="property">classmethod </em><code class="descname">storage_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="torch.html#ByteTensor.storage_type"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#syft.ByteTensor.storage_type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="syft.AutogradClosureFactory">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">AutogradClosureFactory</code><a class="headerlink" href="#syft.AutogradClosureFactory" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">pybind11_builtins.pybind11_object</span></code></p>
</dd></dl>

<dl class="exception">
<dt id="syft.FatalError">
<em class="property">exception </em><code class="descclassname">syft.</code><code class="descname">FatalError</code><a class="headerlink" href="#syft.FatalError" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">Exception</span></code></p>
</dd></dl>

<dl class="class">
<dt id="syft.Generator">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">Generator</code><a class="headerlink" href="#syft.Generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<dl class="method">
<dt id="syft.Generator.get_state">
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.Generator.get_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Generator.initial_seed">
<code class="descname">initial_seed</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.Generator.initial_seed" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Generator.manual_seed">
<code class="descname">manual_seed</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.Generator.manual_seed" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Generator.seed">
<code class="descname">seed</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.Generator.seed" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Generator.set_state">
<code class="descname">set_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.Generator.set_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="syft.Graph">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">Graph</code><a class="headerlink" href="#syft.Graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">pybind11_builtins.pybind11_object</span></code></p>
<dl class="method">
<dt id="syft.Graph.addInput">
<code class="descname">addInput</code><span class="sig-paren">(</span><em>self: torch._C.Graph</em><span class="sig-paren">)</span> &#x2192; torch::jit::Node<a class="headerlink" href="#syft.Graph.addInput" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Graph.advanceStage">
<code class="descname">advanceStage</code><span class="sig-paren">(</span><em>self: torch._C.Graph</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#syft.Graph.advanceStage" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Graph.appendNode">
<code class="descname">appendNode</code><span class="sig-paren">(</span><em>self: torch._C.Graph</em>, <em>arg0: torch::jit::Node</em><span class="sig-paren">)</span> &#x2192; torch::jit::Node<a class="headerlink" href="#syft.Graph.appendNode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Graph.at">
<code class="descname">at</code><span class="sig-paren">(</span><em>g</em>, <em>opname</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.Graph.at" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Graph.constant">
<code class="descname">constant</code><span class="sig-paren">(</span><em>g</em>, <em>value</em>, <em>dims</em>, <em>type</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.Graph.constant" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Graph.create">
<code class="descname">create</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.Graph.create" title="Permalink to this definition">¶</a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic simple">
<li>create(self: torch._C.Graph, arg0: str) -&gt; torch::jit::Node</li>
<li>create(self: torch._C.Graph, arg0: str, arg1: List[torch::jit::Node]) -&gt; torch::jit::Node</li>
</ol>
</dd></dl>

<dl class="method">
<dt id="syft.Graph.createClone">
<code class="descname">createClone</code><span class="sig-paren">(</span><em>self: torch._C.Graph</em>, <em>arg0: torch::jit::Node</em>, <em>arg1: object</em><span class="sig-paren">)</span> &#x2192; torch::jit::Node<a class="headerlink" href="#syft.Graph.createClone" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Graph.createConstant">
<code class="descname">createConstant</code><span class="sig-paren">(</span><em>self: torch._C.Graph</em>, <em>arg0: at::Tensor</em><span class="sig-paren">)</span> &#x2192; torch::jit::Node<a class="headerlink" href="#syft.Graph.createConstant" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Graph.createFusionGroup">
<code class="descname">createFusionGroup</code><span class="sig-paren">(</span><em>self: torch._C.Graph</em><span class="sig-paren">)</span> &#x2192; torch::jit::Node<a class="headerlink" href="#syft.Graph.createFusionGroup" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Graph.createSelect">
<code class="descname">createSelect</code><span class="sig-paren">(</span><em>self: torch._C.Graph</em>, <em>arg0: torch::jit::Node</em>, <em>arg1: int</em><span class="sig-paren">)</span> &#x2192; torch::jit::Node<a class="headerlink" href="#syft.Graph.createSelect" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Graph.eraseInput">
<code class="descname">eraseInput</code><span class="sig-paren">(</span><em>self: torch._C.Graph</em>, <em>arg0: int</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#syft.Graph.eraseInput" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Graph.inputs">
<code class="descname">inputs</code><span class="sig-paren">(</span><em>self: torch._C.Graph</em><span class="sig-paren">)</span> &#x2192; iterator<a class="headerlink" href="#syft.Graph.inputs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Graph.lint">
<code class="descname">lint</code><span class="sig-paren">(</span><em>self: torch._C.Graph</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#syft.Graph.lint" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Graph.nodes">
<code class="descname">nodes</code><span class="sig-paren">(</span><em>self: torch._C.Graph</em><span class="sig-paren">)</span> &#x2192; iterator<a class="headerlink" href="#syft.Graph.nodes" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Graph.op">
<code class="descname">op</code><span class="sig-paren">(</span><em>g</em>, <em>opname</em>, <em>*raw_args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.Graph.op" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an ONNX operator &#8216;opname&#8217;, taking &#8216;args&#8217; as inputs and attributes
&#8216;kwargs&#8217;; returning the node representing the single output of this operator
(see the <cite>outputs</cite> keyword argument for multi-return nodes).</p>
<p>The set of operators and the inputs/attributes they take
is documented at <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md">https://github.com/onnx/onnx/blob/master/docs/Operators.md</a></p>
<p>This function is monkey-patched onto Graph.</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd><p class="first">opname (string): The ONNX operator name, e.g., <cite>Abs</cite> or <cite>Add</cite>.
args (Node...): The inputs to the operator; usually provided</p>
<blockquote>
<div>as arguments to the <cite>symbolic</cite> definition.</div></blockquote>
<dl class="last docutils">
<dt>kwargs: The attributes of the ONNX operator, with keys named</dt>
<dd>according to the following convention: <cite>alpha_f</cite> indicates
the <cite>alpha</cite> attribute with type <cite>f</cite>.  The valid type specifiers are
<cite>f</cite> (float), <cite>i</cite> (int), <cite>s</cite> (string) or <cite>t</cite> (Tensor).  An attribute
specified with type float accepts either a single float, or a
list of floats (e.g., you would say <cite>dims_i</cite> for a <cite>dims</cite> attribute
that takes a list of integers).</dd>
<dt>outputs (int, optional):  The number of outputs this operator returns;</dt>
<dd>by default an operator is assumed to return a single output.
If <cite>outputs</cite> is greater than one, this functions returns a tuple
of output <cite>Node</cite>, representing each output of the ONNX operator
in positional.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="syft.Graph.outputs">
<code class="descname">outputs</code><span class="sig-paren">(</span><em>self: torch._C.Graph</em><span class="sig-paren">)</span> &#x2192; iterator<a class="headerlink" href="#syft.Graph.outputs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Graph.prependNode">
<code class="descname">prependNode</code><span class="sig-paren">(</span><em>self: torch._C.Graph</em>, <em>arg0: torch::jit::Node</em><span class="sig-paren">)</span> &#x2192; torch::jit::Node<a class="headerlink" href="#syft.Graph.prependNode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Graph.registerOutput">
<code class="descname">registerOutput</code><span class="sig-paren">(</span><em>self: torch._C.Graph</em>, <em>arg0: torch::jit::Node</em><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#syft.Graph.registerOutput" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Graph.stage">
<code class="descname">stage</code><span class="sig-paren">(</span><em>self: torch._C.Graph</em><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#syft.Graph.stage" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="syft.Node">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">Node</code><a class="headerlink" href="#syft.Node" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">pybind11_builtins.pybind11_object</span></code></p>
<dl class="method">
<dt id="syft.Node.addInput">
<code class="descname">addInput</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.addInput" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.attributeNames">
<code class="descname">attributeNames</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; List[Symbol]<a class="headerlink" href="#syft.Node.attributeNames" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.cconv">
<code class="descname">cconv</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; str<a class="headerlink" href="#syft.Node.cconv" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.copyAttributes">
<code class="descname">copyAttributes</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: torch::jit::Attributes&lt;torch::jit::Node&gt;</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#syft.Node.copyAttributes" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.debugName">
<code class="descname">debugName</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; str<a class="headerlink" href="#syft.Node.debugName" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.destroy">
<code class="descname">destroy</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#syft.Node.destroy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.f">
<code class="descname">f</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#syft.Node.f" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.f_">
<code class="descname">f_</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em>, <em>arg1: float</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.f_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.fs">
<code class="descname">fs</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em><span class="sig-paren">)</span> &#x2192; List[float]<a class="headerlink" href="#syft.Node.fs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.fs_">
<code class="descname">fs_</code><span class="sig-paren">(</span><em>self: torch._C.Node, arg0: str, arg1: List[float]</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.fs_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.g">
<code class="descname">g</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em><span class="sig-paren">)</span> &#x2192; torch._C.Graph<a class="headerlink" href="#syft.Node.g" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.g_">
<code class="descname">g_</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em>, <em>arg1: torch._C.Graph</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.g_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.gs">
<code class="descname">gs</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em><span class="sig-paren">)</span> &#x2192; List[torch._C.Graph]<a class="headerlink" href="#syft.Node.gs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.gs_">
<code class="descname">gs_</code><span class="sig-paren">(</span><em>self: torch._C.Node, arg0: str, arg1: List[torch._C.Graph]</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.gs_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.hasAttribute">
<code class="descname">hasAttribute</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: Symbol</em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#syft.Node.hasAttribute" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.hasAttributes">
<code class="descname">hasAttributes</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#syft.Node.hasAttributes" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.hasMultipleOutputs">
<code class="descname">hasMultipleOutputs</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#syft.Node.hasMultipleOutputs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.hasType">
<code class="descname">hasType</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#syft.Node.hasType" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.i">
<code class="descname">i</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#syft.Node.i" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.i_">
<code class="descname">i_</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em>, <em>arg1: int</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.i_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.inferTypeFrom">
<code class="descname">inferTypeFrom</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: at::Tensor</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#syft.Node.inferTypeFrom" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.input">
<code class="descname">input</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.Node.input" title="Permalink to this definition">¶</a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic simple">
<li>input(self: torch._C.Node) -&gt; torch._C.Node</li>
<li>input(self: torch._C.Node, arg0: int) -&gt; torch._C.Node</li>
</ol>
</dd></dl>

<dl class="method">
<dt id="syft.Node.inputs">
<code class="descname">inputs</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; iterator<a class="headerlink" href="#syft.Node.inputs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.insertAfter">
<code class="descname">insertAfter</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.insertAfter" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.insertBefore">
<code class="descname">insertBefore</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.insertBefore" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.is">
<code class="descname">is</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em><span class="sig-paren">)</span> &#x2192; List[int]<a class="headerlink" href="#syft.Node.is" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.is_">
<code class="descname">is_</code><span class="sig-paren">(</span><em>self: torch._C.Node, arg0: str, arg1: List[int]</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.is_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.kind">
<code class="descname">kind</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; Symbol<a class="headerlink" href="#syft.Node.kind" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.kindOf">
<code class="descname">kindOf</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: Symbol</em><span class="sig-paren">)</span> &#x2192; AttributeKind<a class="headerlink" href="#syft.Node.kindOf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.moveAfter">
<code class="descname">moveAfter</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#syft.Node.moveAfter" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.moveBefore">
<code class="descname">moveBefore</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#syft.Node.moveBefore" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.offset">
<code class="descname">offset</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#syft.Node.offset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.outputs">
<code class="descname">outputs</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; List[torch._C.Node]<a class="headerlink" href="#syft.Node.outputs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.pyname">
<code class="descname">pyname</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; str<a class="headerlink" href="#syft.Node.pyname" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.pyobj">
<code class="descname">pyobj</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; object<a class="headerlink" href="#syft.Node.pyobj" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.removeAllInputs">
<code class="descname">removeAllInputs</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#syft.Node.removeAllInputs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.removeAttribute">
<code class="descname">removeAttribute</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: Symbol</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.removeAttribute" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.removeInput">
<code class="descname">removeInput</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: int</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#syft.Node.removeInput" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.replaceAllUsesWith">
<code class="descname">replaceAllUsesWith</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#syft.Node.replaceAllUsesWith" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.replaceInput">
<code class="descname">replaceInput</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: int</em>, <em>arg1: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.replaceInput" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.replaceInputWith">
<code class="descname">replaceInputWith</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: torch._C.Node</em>, <em>arg1: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#syft.Node.replaceInputWith" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.s">
<code class="descname">s</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em><span class="sig-paren">)</span> &#x2192; str<a class="headerlink" href="#syft.Node.s" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.s_">
<code class="descname">s_</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em>, <em>arg1: str</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.s_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.scalar_args">
<code class="descname">scalar_args</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; list<a class="headerlink" href="#syft.Node.scalar_args" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.setDebugName">
<code class="descname">setDebugName</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.setDebugName" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.setStage">
<code class="descname">setStage</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: int</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.setStage" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.setType">
<code class="descname">setType</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: torch::jit::Type</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.setType" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.setTypeAs">
<code class="descname">setTypeAs</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.setTypeAs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.ss">
<code class="descname">ss</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em><span class="sig-paren">)</span> &#x2192; List[str]<a class="headerlink" href="#syft.Node.ss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.ss_">
<code class="descname">ss_</code><span class="sig-paren">(</span><em>self: torch._C.Node, arg0: str, arg1: List[str]</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.ss_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.stage">
<code class="descname">stage</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.Node.stage" title="Permalink to this definition">¶</a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic simple">
<li>stage(self: torch._C.Node) -&gt; int</li>
<li>stage(self: torch._C.Node) -&gt; int</li>
</ol>
</dd></dl>

<dl class="method">
<dt id="syft.Node.t">
<code class="descname">t</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em><span class="sig-paren">)</span> &#x2192; at::Tensor<a class="headerlink" href="#syft.Node.t" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.t_">
<code class="descname">t_</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em>, <em>arg1: at::Tensor</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.t_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.ts">
<code class="descname">ts</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em><span class="sig-paren">)</span> &#x2192; List[at::Tensor]<a class="headerlink" href="#syft.Node.ts" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.ts_">
<code class="descname">ts_</code><span class="sig-paren">(</span><em>self: torch._C.Node, arg0: str, arg1: List[at::Tensor]</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.ts_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.type">
<code class="descname">type</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; torch::jit::Type<a class="headerlink" href="#syft.Node.type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.typeOption">
<code class="descname">typeOption</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; torch::jit::Type<a class="headerlink" href="#syft.Node.typeOption" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.unique">
<code class="descname">unique</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#syft.Node.unique" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.uniqueName">
<code class="descname">uniqueName</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; str<a class="headerlink" href="#syft.Node.uniqueName" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.uses">
<code class="descname">uses</code><span class="sig-paren">(</span><em>self: torch._C.Node</em><span class="sig-paren">)</span> &#x2192; List[torch::jit::Use]<a class="headerlink" href="#syft.Node.uses" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.z">
<code class="descname">z</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em><span class="sig-paren">)</span> &#x2192; at::Tensor<a class="headerlink" href="#syft.Node.z" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.z_">
<code class="descname">z_</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em>, <em>arg1: at::Tensor</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.z_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.zs">
<code class="descname">zs</code><span class="sig-paren">(</span><em>self: torch._C.Node</em>, <em>arg0: str</em><span class="sig-paren">)</span> &#x2192; List[at::Tensor]<a class="headerlink" href="#syft.Node.zs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Node.zs_">
<code class="descname">zs_</code><span class="sig-paren">(</span><em>self: torch._C.Node, arg0: str, arg1: List[at::Tensor]</em><span class="sig-paren">)</span> &#x2192; torch._C.Node<a class="headerlink" href="#syft.Node.zs_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="syft.Size">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">Size</code><a class="headerlink" href="#syft.Size" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">tuple</span></code></p>
</dd></dl>

<dl class="class">
<dt id="syft.TracingState">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">TracingState</code><a class="headerlink" href="#syft.TracingState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">pybind11_builtins.pybind11_object</span></code></p>
<dl class="method">
<dt id="syft.TracingState.export">
<code class="descname">export</code><span class="sig-paren">(</span><em>self: torch._C.TracingState, arg0: List[at::Tensor], arg1: int</em><span class="sig-paren">)</span> &#x2192; bytes<a class="headerlink" href="#syft.TracingState.export" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.TracingState.graph">
<code class="descname">graph</code><span class="sig-paren">(</span><em>self: torch._C.TracingState</em><span class="sig-paren">)</span> &#x2192; torch._C.Graph<a class="headerlink" href="#syft.TracingState.graph" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="syft.TracingState.is_complete">
<code class="descname">is_complete</code><a class="headerlink" href="#syft.TracingState.is_complete" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="syft.TracingState.is_expired">
<code class="descname">is_expired</code><a class="headerlink" href="#syft.TracingState.is_expired" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="syft.Type">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">Type</code><a class="headerlink" href="#syft.Type" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">pybind11_builtins.pybind11_object</span></code></p>
<dl class="method">
<dt id="syft.Type.contiguous">
<code class="descname">contiguous</code><span class="sig-paren">(</span><em>self: torch._C.Type</em><span class="sig-paren">)</span> &#x2192; torch._C.Type<a class="headerlink" href="#syft.Type.contiguous" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Type.kind">
<code class="descname">kind</code><span class="sig-paren">(</span><em>self: torch._C.Type</em><span class="sig-paren">)</span> &#x2192; str<a class="headerlink" href="#syft.Type.kind" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Type.scalarType">
<code class="descname">scalarType</code><span class="sig-paren">(</span><em>self: torch._C.Type</em><span class="sig-paren">)</span> &#x2192; str<a class="headerlink" href="#syft.Type.scalarType" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Type.sizes">
<code class="descname">sizes</code><span class="sig-paren">(</span><em>self: torch._C.Type</em><span class="sig-paren">)</span> &#x2192; List[int]<a class="headerlink" href="#syft.Type.sizes" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="syft.Type.strides">
<code class="descname">strides</code><span class="sig-paren">(</span><em>self: torch._C.Type</em><span class="sig-paren">)</span> &#x2192; List[int]<a class="headerlink" href="#syft.Type.strides" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="syft.Use">
<em class="property">class </em><code class="descclassname">syft.</code><code class="descname">Use</code><a class="headerlink" href="#syft.Use" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">pybind11_builtins.pybind11_object</span></code></p>
<dl class="attribute">
<dt id="syft.Use.offset">
<code class="descname">offset</code><a class="headerlink" href="#syft.Use.offset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="syft.Use.user">
<code class="descname">user</code><a class="headerlink" href="#syft.Use.user" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="syft.abs">
<code class="descclassname">syft.</code><code class="descname">abs</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.abs" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the element-wise absolute value of the given <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> a tensor.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="go">FloatTensor([1, 2, 3])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.acos">
<code class="descclassname">syft.</code><code class="descname">acos</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.acos" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the arccosine  of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">acos</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go"> 2.2608</span>
<span class="go"> 1.2956</span>
<span class="go"> 1.1075</span>
<span class="go">    nan</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.add">
<code class="descclassname">syft.</code><code class="descname">add</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.add" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">add</code><span class="sig-paren">(</span><em>input</em>, <em>value</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Adds the scalar <code class="xref py py-attr docutils literal"><span class="pre">value</span></code> to each element of the input <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>
and returns a new resulting tensor.</p>
<p><span class="math">\(out = tensor + value\)</span></p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is of type FloatTensor or DoubleTensor, <code class="xref py py-attr docutils literal"><span class="pre">value</span></code> must be
a real number, otherwise it should be an integer.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
value (Number): the number to be added to each element of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.4050</span>
<span class="go">-1.2227</span>
<span class="go"> 1.8688</span>
<span class="go">-0.4185</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="go"> 20.4050</span>
<span class="go"> 18.7773</span>
<span class="go"> 21.8688</span>
<span class="go"> 19.5815</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">add</code><span class="sig-paren">(</span><em>input</em>, <em>value=1</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Each element of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> is multiplied by the scalar
<code class="xref py py-attr docutils literal"><span class="pre">value</span></code> and added to each element of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.
The resulting Tensor is returned.</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> must be
<span class="xref std std-ref">broadcastable</span>.</p>
<p><span class="math">\(out = input + (other * value)\)</span></p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> is of type FloatTensor or DoubleTensor, <code class="xref py py-attr docutils literal"><span class="pre">value</span></code> must be
a real number, otherwise it should be an integer.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the first input <cite>Tensor</cite>
value (Number): the scalar multiplier for <code class="xref py py-attr docutils literal"><span class="pre">other</span></code>
other (Tensor): the second input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.9310</span>
<span class="go"> 2.0330</span>
<span class="go"> 0.0852</span>
<span class="go">-0.2941</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>

<span class="go"> 1.0663  0.2544</span>
<span class="go">-0.1513  0.0749</span>
<span class="go">[torch.FloatTensor of size 2x2]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="go"> 9.7322</span>
<span class="go"> 4.5770</span>
<span class="go">-1.4279</span>
<span class="go"> 0.4552</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.addbmm">
<code class="descclassname">syft.</code><code class="descname">addbmm</code><span class="sig-paren">(</span><em>beta=1</em>, <em>mat</em>, <em>alpha=1</em>, <em>batch1</em>, <em>batch2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.addbmm" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a batch matrix-matrix product of matrices stored
in <code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code>,
with a reduced add step (all matrix multiplications get accumulated
along the first dimension).
<code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> is added to the final result.</p>
<p><code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code> must be 3D Tensors each containing the
same number of matrices.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code> is a <cite>b x n x m</cite> Tensor, <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code> is a <cite>b x m x p</cite>
Tensor, :<code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> must be <span class="xref std std-ref">broadcastable</span>
with a <cite>n x p</cite> Tensor and attr:<cite>out</cite> will be a <cite>n x p</cite> Tensor.</p>
<p>In other words,
<span class="math">\(res = (beta * M) + (alpha * sum(batch1_i &#64; batch2_i, i = 0, b))\)</span></p>
<p>For inputs of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, args <cite>beta</cite> and <cite>alpha</cite>
must be real numbers, otherwise they should be integers.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>beta (Number, optional): multiplier for <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code>
mat (Tensor): matrix to be added
alpha (Number, optional): multiplier for <cite>batch1 &#64; batch2</cite>
batch1 (Tensor): First batch of matrices to be multiplied
batch2 (Tensor): Second batch of matrices to be multiplied
out (Tensor, optional): Output tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">addbmm</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">)</span>

<span class="go"> -3.1162  11.0071   7.3102   0.1824  -7.6892</span>
<span class="go">  1.8265   6.0739   0.4589  -0.5641  -5.4283</span>
<span class="go"> -9.3387  -0.1794  -1.2318  -6.8841  -4.7239</span>
<span class="go">[torch.FloatTensor of size 3x5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.addcdiv">
<code class="descclassname">syft.</code><code class="descname">addcdiv</code><span class="sig-paren">(</span><em>tensor</em>, <em>value=1</em>, <em>tensor1</em>, <em>tensor2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.addcdiv" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the element-wise division of <code class="xref py py-attr docutils literal"><span class="pre">tensor1</span></code> by <code class="xref py py-attr docutils literal"><span class="pre">tensor2</span></code>,
multiply the result by the scalar <code class="xref py py-attr docutils literal"><span class="pre">value</span></code> and add it to <code class="xref py py-attr docutils literal"><span class="pre">tensor</span></code>.</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">tensor</span></code>, <code class="xref py py-attr docutils literal"><span class="pre">tensor1</span></code>, and <code class="xref py py-attr docutils literal"><span class="pre">tensor2</span></code> must be
<span class="xref std std-ref">broadcastable</span>.</p>
<p>For inputs of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, <code class="xref py py-attr docutils literal"><span class="pre">value</span></code> must be
a real number, otherwise an integer.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>tensor (Tensor): the tensor to be added
value (Number, optional): multiplier for <cite>tensor1 ./ tensor2</cite>
tensor1 (Tensor): Numerator tensor
tensor2 (Tensor): Denominator tensor
out (Tensor, optional): Output tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">addcdiv</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">)</span>

<span class="go"> 0.0122 -0.0188 -0.2354</span>
<span class="go"> 0.7396 -1.5721  1.2878</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.addcmul">
<code class="descclassname">syft.</code><code class="descname">addcmul</code><span class="sig-paren">(</span><em>tensor</em>, <em>value=1</em>, <em>tensor1</em>, <em>tensor2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.addcmul" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the element-wise multiplication of <code class="xref py py-attr docutils literal"><span class="pre">tensor1</span></code>
by <code class="xref py py-attr docutils literal"><span class="pre">tensor2</span></code>, multiply the result by the scalar <code class="xref py py-attr docutils literal"><span class="pre">value</span></code>
and add it to <code class="xref py py-attr docutils literal"><span class="pre">tensor</span></code>.</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">tensor</span></code>, <code class="xref py py-attr docutils literal"><span class="pre">tensor1</span></code>, and <code class="xref py py-attr docutils literal"><span class="pre">tensor2</span></code> must be
<span class="xref std std-ref">broadcastable</span>.</p>
<p>For inputs of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, <code class="xref py py-attr docutils literal"><span class="pre">value</span></code> must be
a real number, otherwise an integer.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>tensor (Tensor): the tensor to be added
value (Number, optional): multiplier for <cite>tensor1 .* tensor2</cite>
tensor1 (Tensor): tensor to be multiplied
tensor2 (Tensor): tensor to be multiplied
out (Tensor, optional): Output tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">addcmul</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">)</span>

<span class="go"> 0.0122 -0.0188 -0.2354</span>
<span class="go"> 0.7396 -1.5721  1.2878</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.addmm">
<code class="descclassname">syft.</code><code class="descname">addmm</code><span class="sig-paren">(</span><em>beta=1</em>, <em>mat</em>, <em>alpha=1</em>, <em>mat1</em>, <em>mat2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.addmm" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a matrix multiplication of the matrices <code class="xref py py-attr docutils literal"><span class="pre">mat1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">mat2</span></code>.
The matrix <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> is added to the final result.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">mat1</span></code> is a <cite>n x m</cite> Tensor, <code class="xref py py-attr docutils literal"><span class="pre">mat2</span></code> is a <cite>m x p</cite> Tensor,
then <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> must be <span class="xref std std-ref">broadcastable</span> with
a <cite>n x p</cite> Tensor and <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will be a <cite>n x p</cite> Tensor.</p>
<p><cite>alpha</cite> and <cite>beta</cite> are scaling factors on <cite>mat1 &#64; mat2</cite> and <cite>mat</cite> respectively.</p>
<p>In other words,
<span class="math">\(out = (beta * M) + (alpha * mat1 &#64; mat2)\)</span></p>
<p>For inputs of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, args <code class="xref py py-attr docutils literal"><span class="pre">beta</span></code> and
<code class="xref py py-attr docutils literal"><span class="pre">alpha</span></code> must be real numbers, otherwise they should be integers.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>beta (Number, optional): multiplier for <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code>
mat (Tensor): matrix to be added
alpha (Number, optional): multiplier for <cite>mat1 &#64; mat2</cite>
mat1 (Tensor): First matrix to be multiplied
mat2 (Tensor): Second matrix to be multiplied
out (Tensor, optional): Output tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mat1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mat2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">addmm</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">)</span>

<span class="go">-0.4095 -1.9703  1.3561</span>
<span class="go"> 5.7674 -4.9760  2.7378</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.addmv">
<code class="descclassname">syft.</code><code class="descname">addmv</code><span class="sig-paren">(</span><em>beta=1</em>, <em>tensor</em>, <em>alpha=1</em>, <em>mat</em>, <em>vec</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.addmv" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a matrix-vector product of the matrix <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> and
the vector <code class="xref py py-attr docutils literal"><span class="pre">vec</span></code>.
The vector <code class="xref py py-attr docutils literal"><span class="pre">tensor</span></code> is added to the final result.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> is a <cite>n x m</cite> Tensor, <code class="xref py py-attr docutils literal"><span class="pre">vec</span></code> is a 1D Tensor of size <cite>m</cite>,
then <code class="xref py py-attr docutils literal"><span class="pre">tensor</span></code> must be <span class="xref std std-ref">broadcastable</span>
with a 1D tensor of size <cite>n</cite> and <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will be 1D tensor of size <cite>n</cite>.</p>
<p><cite>alpha</cite> and <cite>beta</cite> are scaling factors on <cite>mat * vec</cite> and <cite>tensor</cite> respectively.</p>
<p>In other words:</p>
<p><span class="math">\(out = (beta * tensor) + (alpha * (mat &#64; vec2))\)</span></p>
<p>For inputs of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, args <code class="xref py py-attr docutils literal"><span class="pre">beta</span></code> and
<code class="xref py py-attr docutils literal"><span class="pre">alpha</span></code> must be real numbers, otherwise they should be integers</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>beta (Number, optional): multiplier for <code class="xref py py-attr docutils literal"><span class="pre">tensor</span></code>
tensor (Tensor): vector to be added
alpha (Number, optional): multiplier for <cite>mat &#64; vec</cite>
mat (Tensor): matrix to be multiplied
vec (Tensor): vector to be multiplied
out (Tensor, optional): Output tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">addmv</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">mat</span><span class="p">,</span> <span class="n">vec</span><span class="p">)</span>

<span class="go">-2.0939</span>
<span class="go">-2.2950</span>
<span class="go">[torch.FloatTensor of size 2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.addr">
<code class="descclassname">syft.</code><code class="descname">addr</code><span class="sig-paren">(</span><em>beta=1</em>, <em>mat</em>, <em>alpha=1</em>, <em>vec1</em>, <em>vec2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.addr" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the outer-product of vectors <code class="xref py py-attr docutils literal"><span class="pre">vec1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">vec2</span></code>
and adds it to the matrix <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code>.</p>
<p>Optional values <code class="xref py py-attr docutils literal"><span class="pre">beta</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">alpha</span></code> are scalars that multiply
<code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> and <span class="math">\((vec1 \otimes vec2)\)</span> respectively</p>
<p>In other words,
<span class="math">\(out = (beta * mat) + (alpha * vec1 \otimes vec2)\)</span></p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">vec1</span></code> is a vector of size <cite>n</cite> and <code class="xref py py-attr docutils literal"><span class="pre">vec2</span></code> is a vector
of size <cite>m</cite>, then <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> must be
<span class="xref std std-ref">broadcastable</span> with a matrix of size <cite>n x m</cite>
and <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will be a matrix of size <cite>n x m</cite>.</p>
<p>For inputs of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, args <code class="xref py py-attr docutils literal"><span class="pre">beta</span></code> and
<code class="xref py py-attr docutils literal"><span class="pre">alpha</span></code> must be real numbers, otherwise they should be integers</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">beta (Number, optional): Multiplier for <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code>
mat (Tensor): Matrix to be added
alpha (Number, optional): Multiplier for outer product of</p>
<blockquote>
<div>for <code class="xref py py-attr docutils literal"><span class="pre">vec1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">vec2</span></code></div></blockquote>
<p class="last">vec1 (Tensor): First vector of the outer product
vec2 (Tensor): Second vector of the outer product
out (Tensor, optional): Output tensor</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">vec1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vec2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">addr</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">vec1</span><span class="p">,</span> <span class="n">vec2</span><span class="p">)</span>
<span class="go"> 1  2</span>
<span class="go"> 2  4</span>
<span class="go"> 3  6</span>
<span class="go">[torch.FloatTensor of size 3x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.arange">
<code class="descclassname">syft.</code><code class="descname">arange</code><span class="sig-paren">(</span><em>start=0</em>, <em>end</em>, <em>step=1</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.arange" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a 1D Tensor of size <span class="math">\(floor((end - start) / step)\)</span> with values
from the interval <code class="docutils literal"><span class="pre">[start,</span> <span class="pre">end)</span></code> taken with step <code class="xref py py-attr docutils literal"><span class="pre">step</span></code> starting
from <cite>start</cite>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>start (float): The starting value for the set of points
end (float): The ending value for the set of points
step (float): The gap between each pair of adjacent points
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="go"> 0</span>
<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go">[torch.FloatTensor of size 3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="go"> 1.0000</span>
<span class="go"> 1.5000</span>
<span class="go"> 2.0000</span>
<span class="go">[torch.FloatTensor of size 3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.asin">
<code class="descclassname">syft.</code><code class="descname">asin</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.asin" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the arcsine  of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">asin</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">-0.6900</span>
<span class="go"> 0.2752</span>
<span class="go"> 0.4633</span>
<span class="go">    nan</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.atan">
<code class="descclassname">syft.</code><code class="descname">atan</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.atan" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the arctangent  of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">atan</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">-0.5669</span>
<span class="go"> 0.2653</span>
<span class="go"> 0.4203</span>
<span class="go"> 0.9196</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.atan2">
<code class="descclassname">syft.</code><code class="descname">atan2</code><span class="sig-paren">(</span><em>input1</em>, <em>input2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.atan2" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the arctangent of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input1</span></code>
and <code class="xref py py-attr docutils literal"><span class="pre">input2</span></code>.</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">input1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">input2</span></code> must be
<span class="xref std std-ref">broadcastable</span>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input1 (Tensor): the first input <cite>Tensor</cite>
input2 (Tensor): the second input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">atan2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
<span class="go">-2.4167</span>
<span class="go"> 2.9755</span>
<span class="go"> 0.9363</span>
<span class="go"> 1.6613</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.baddbmm">
<code class="descclassname">syft.</code><code class="descname">baddbmm</code><span class="sig-paren">(</span><em>beta=1</em>, <em>mat</em>, <em>alpha=1</em>, <em>batch1</em>, <em>batch2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.baddbmm" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a batch matrix-matrix product of matrices in <code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code>
and <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code>.
<code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> is added to the final result.</p>
<p><code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code> must be 3D Tensors each containing the same
number of matrices.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code> is a <cite>b x n x m</cite> Tensor, <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code> is a <cite>b x m x p</cite>
Tensor, then <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> must be <span class="xref std std-ref">broadcastable</span>
with a <cite>b x n x p</cite> Tensor and <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will be a <cite>b x n x p</cite> Tensor.</p>
<p>In other words,
<span class="math">\(res_i = (beta * M_i) + (alpha * batch1_i \times batch2_i)\)</span></p>
<p>For inputs of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, args <code class="xref py py-attr docutils literal"><span class="pre">beta</span></code> and
<code class="xref py py-attr docutils literal"><span class="pre">alpha</span></code> must be real numbers, otherwise they should be integers.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>beta (Number, optional): multiplier for <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code>
mat (Tensor): tensor to be added
alpha (Number, optional): multiplier for <cite>batch1 &#64; batch2</cite>
batch1 (Tensor): First batch of matrices to be multiplied
batch2 (Tensor): Second batch of matrices to be multiplied
out (Tensor, optional): Output tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">baddbmm</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">torch.Size([10, 3, 5])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.bernoulli">
<code class="descclassname">syft.</code><code class="descname">bernoulli</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.bernoulli" title="Permalink to this definition">¶</a></dt>
<dd><p>Draws binary random numbers (0 or 1) from a bernoulli distribution.</p>
<p>The <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor should be a tensor containing probabilities
to be used for drawing the binary random number.
Hence, all values in <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> have to be in the range:
<span class="math">\(0 &lt;= input_i &lt;= 1\)</span></p>
<p>The <cite>i-th</cite> element of the output tensor will draw a value <cite>1</cite> according
to the <cite>i-th</cite> probability value given in <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<p>The returned <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> Tensor only has values 0 or 1 and is of the same
shape as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code></p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): Probability values for the bernoulli distribution
out (Tensor, optional): Output tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># generate a uniform random matrix with range [0, 1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.7544  0.8140  0.9842</span>
<span class="go"> 0.5282  0.0595  0.6445</span>
<span class="go"> 0.1925  0.9553  0.9732</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 1  1  1</span>
<span class="go"> 0  0  1</span>
<span class="go"> 0  1  1</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># probability of drawing &quot;1&quot; is 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 1  1  1</span>
<span class="go"> 1  1  1</span>
<span class="go"> 1  1  1</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># probability of drawing &quot;1&quot; is 0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 0  0  0</span>
<span class="go"> 0  0  0</span>
<span class="go"> 0  0  0</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.bmm">
<code class="descclassname">syft.</code><code class="descname">bmm</code><span class="sig-paren">(</span><em>batch1</em>, <em>batch2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.bmm" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a batch matrix-matrix product of matrices stored in <code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code>
and <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code>.</p>
<p><code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code> must be 3D Tensors each containing
the same number of matrices.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code> is a <cite>b x n x m</cite> Tensor, <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code> is a <cite>b x m x p</cite>
Tensor, <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will be a <cite>b x n x p</cite> Tensor.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This function does not <span class="xref std std-ref">broadcast</span>.
For broadcasting matrix products, see <code class="xref py py-func docutils literal"><span class="pre">torch.matmul()</span></code>.</p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd>batch1 (Tensor): First batch of matrices to be multiplied
batch2 (Tensor): Second batch of matrices to be multiplied
out (Tensor, optional): Output tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">torch.Size([10, 3, 5])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.btrifact">
<code class="descclassname">syft.</code><code class="descname">btrifact</code><span class="sig-paren">(</span><em>A</em>, <em>info=None</em>, <em>pivot=True</em><span class="sig-paren">)</span> &#x2192; Tensor, IntTensor<a class="headerlink" href="#syft.btrifact" title="Permalink to this definition">¶</a></dt>
<dd><p>Batch LU factorization.</p>
<p>Returns a tuple containing the LU factorization and pivots.
The optional argument <cite>info</cite> provides information if the
factorization succeeded for each minibatch example.
The info values are from dgetrf and a non-zero value indicates an error
occurred. The specific values are from cublas if cuda is being used, otherwise
LAPACK. Pivoting is done if pivot is set.</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>A (Tensor): tensor to factor.</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_LU</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">btrifact</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.btrisolve">
<code class="descclassname">syft.</code><code class="descname">btrisolve</code><span class="sig-paren">(</span><em>b</em>, <em>LU_data</em>, <em>LU_pivots</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.btrisolve" title="Permalink to this definition">¶</a></dt>
<dd><p>Batch LU solve.</p>
<p>Returns the LU solve of the linear system Ax = b.</p>
<dl class="docutils">
<dt>Arguments:</dt>
<dd>b (Tensor): RHS tensor.
LU_data (Tensor): Pivoted LU factorization of A from btrifact.
LU_pivots (IntTensor): Pivots of the LU factorization.</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_LU</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">btrifact</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">btrisolve</span><span class="p">(</span><span class="o">*</span><span class="n">A_LU</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span>
<span class="go">6.664001874625056e-08</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.cat">
<code class="descclassname">syft.</code><code class="descname">cat</code><span class="sig-paren">(</span><em>seq</em>, <em>dim=0</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.cat" title="Permalink to this definition">¶</a></dt>
<dd><p>Concatenates the given sequence of <code class="xref py py-attr docutils literal"><span class="pre">seq</span></code> Tensors in the given dimension.</p>
<p><code class="xref py py-func docutils literal"><span class="pre">torch.cat()</span></code> can be seen as an inverse operation for <code class="xref py py-func docutils literal"><span class="pre">torch.split()</span></code>
and <code class="xref py py-func docutils literal"><span class="pre">torch.chunk()</span></code></p>
<p><a class="reference internal" href="../index.html#syft.cat" title="syft.cat"><code class="xref py py-func docutils literal"><span class="pre">cat()</span></code></a> can be best understood via examples.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first docutils">
<dt>seq (sequence of Tensors): Can be any python sequence of <cite>Tensor</cite></dt>
<dd>of the same type.</dd>
</dl>
<p class="last">dim (int, optional): The dimension over which the tensors are concatenated
out (Tensor, optional): Output argument</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 0.5983 -0.0341  2.4918</span>
<span class="go"> 1.5981 -0.5265 -0.8735</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>

<span class="go"> 0.5983 -0.0341  2.4918</span>
<span class="go"> 1.5981 -0.5265 -0.8735</span>
<span class="go"> 0.5983 -0.0341  2.4918</span>
<span class="go"> 1.5981 -0.5265 -0.8735</span>
<span class="go"> 0.5983 -0.0341  2.4918</span>
<span class="go"> 1.5981 -0.5265 -0.8735</span>
<span class="go">[torch.FloatTensor of size 6x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>

<span class="go"> 0.5983 -0.0341  2.4918  0.5983 -0.0341  2.4918  0.5983 -0.0341  2.4918</span>
<span class="go"> 1.5981 -0.5265 -0.8735  1.5981 -0.5265 -0.8735  1.5981 -0.5265 -0.8735</span>
<span class="go">[torch.FloatTensor of size 2x9]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.ceil">
<code class="descclassname">syft.</code><code class="descname">ceil</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.ceil" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the ceil of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>,
the smallest integer greater than or equal to each element.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 2</span>
<span class="go"> 1</span>
<span class="go">-0</span>
<span class="go">-0</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.clamp">
<code class="descclassname">syft.</code><code class="descname">clamp</code><span class="sig-paren">(</span><em>input</em>, <em>min</em>, <em>max</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.clamp" title="Permalink to this definition">¶</a></dt>
<dd><p>Clamp all elements in <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> into the range <cite>[min, max]</cite> and return
a resulting Tensor.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>      <span class="o">|</span> <span class="nb">min</span><span class="p">,</span> <span class="k">if</span> <span class="n">x_i</span> <span class="o">&lt;</span> <span class="nb">min</span>
<span class="n">y_i</span> <span class="o">=</span> <span class="o">|</span> <span class="n">x_i</span><span class="p">,</span> <span class="k">if</span> <span class="nb">min</span> <span class="o">&lt;=</span> <span class="n">x_i</span> <span class="o">&lt;=</span> <span class="nb">max</span>
      <span class="o">|</span> <span class="nb">max</span><span class="p">,</span> <span class="k">if</span> <span class="n">x_i</span> <span class="o">&gt;</span> <span class="nb">max</span>
</pre></div>
</div>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, args <a class="reference internal" href="../index.html#syft.min" title="syft.min"><code class="xref py py-attr docutils literal"><span class="pre">min</span></code></a>
and <a class="reference internal" href="../index.html#syft.max" title="syft.max"><code class="xref py py-attr docutils literal"><span class="pre">max</span></code></a> must be real numbers, otherwise they should be integers</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
min (Number): lower-bound of the range to be clamped to
max (Number): upper-bound of the range to be clamped to
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mf">0.5</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"> 0.5000</span>
<span class="go"> 0.3912</span>
<span class="go">-0.5000</span>
<span class="go">-0.5000</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">clamp</code><span class="sig-paren">(</span><em>input</em>, <em>*</em>, <em>min</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Clamps all elements in <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> to be larger or equal <a class="reference internal" href="../index.html#syft.min" title="syft.min"><code class="xref py py-attr docutils literal"><span class="pre">min</span></code></a>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, <code class="xref py py-attr docutils literal"><span class="pre">value</span></code>
should be a real number, otherwise it should be an integer</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
value (Number): minimal value of each element in the output
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.5000</span>
<span class="go"> 0.5000</span>
<span class="go"> 0.5000</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">clamp</code><span class="sig-paren">(</span><em>input</em>, <em>*</em>, <em>max</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Clamps all elements in <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> to be smaller or equal <a class="reference internal" href="../index.html#syft.max" title="syft.max"><code class="xref py py-attr docutils literal"><span class="pre">max</span></code></a>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, <code class="xref py py-attr docutils literal"><span class="pre">value</span></code>
should be a real number, otherwise it should be an integer</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
value (Number): maximal value of each element in the output
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"> 0.5000</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.cos">
<code class="descclassname">syft.</code><code class="descname">cos</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.cos" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the cosine  of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go"> 0.8041</span>
<span class="go"> 0.9633</span>
<span class="go"> 0.9018</span>
<span class="go"> 0.2557</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.cosh">
<code class="descclassname">syft.</code><code class="descname">cosh</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.cosh" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the hyperbolic cosine  of the elements of
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cosh</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go"> 1.2095</span>
<span class="go"> 1.0372</span>
<span class="go"> 1.1015</span>
<span class="go"> 1.9917</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.cross">
<code class="descclassname">syft.</code><code class="descname">cross</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>dim=-1</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.cross" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the cross product of vectors in dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>
and <code class="xref py py-attr docutils literal"><span class="pre">other</span></code>.</p>
<p><code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> must have the same size, and the size of their
<code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> dimension should be 3.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is not given, it defaults to the first dimension found with the
size 3.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
other (Tensor): the second input <cite>Tensor</cite>
dim  (int, optional): the dimension to take the cross-product in.
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.6652 -1.0116 -0.6857</span>
<span class="go"> 0.2286  0.4446 -0.5272</span>
<span class="go"> 0.0476  0.2321  1.9991</span>
<span class="go"> 0.6199  1.1924 -0.9397</span>
<span class="go">[torch.FloatTensor of size 4x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>

<span class="go">-0.1042 -1.1156  0.1947</span>
<span class="go"> 0.9947  0.1149  0.4701</span>
<span class="go">-1.0108  0.8319 -0.0750</span>
<span class="go"> 0.9045 -1.3754  1.0976</span>
<span class="go">[torch.FloatTensor of size 4x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cross</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="go">-0.9619  0.2009  0.6367</span>
<span class="go"> 0.2696 -0.6318 -0.4160</span>
<span class="go">-1.6805 -2.0171  0.2741</span>
<span class="go"> 0.0163 -1.5304 -1.9311</span>
<span class="go">[torch.FloatTensor of size 4x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cross</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="go">-0.9619  0.2009  0.6367</span>
<span class="go"> 0.2696 -0.6318 -0.4160</span>
<span class="go">-1.6805 -2.0171  0.2741</span>
<span class="go"> 0.0163 -1.5304 -1.9311</span>
<span class="go">[torch.FloatTensor of size 4x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.cumprod">
<code class="descclassname">syft.</code><code class="descname">cumprod</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.cumprod" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the cumulative product of elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> in the dimension
<code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>.</p>
<p>For example, if <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is a vector of size N, the result will also be
a vector of size N, with elements:
<span class="math">\(y_i = x_1 * x_2 * x_3 * ... * x_i\)</span></p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
dim  (int): the dimension to do the operation over
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.1148</span>
<span class="go"> 1.8423</span>
<span class="go"> 1.4143</span>
<span class="go">-0.4403</span>
<span class="go"> 1.2859</span>
<span class="go">-1.2514</span>
<span class="go">-0.4748</span>
<span class="go"> 1.1735</span>
<span class="go">-1.6332</span>
<span class="go">-0.4272</span>
<span class="go">[torch.FloatTensor of size 10]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="go"> 1.1148</span>
<span class="go"> 2.0537</span>
<span class="go"> 2.9045</span>
<span class="go">-1.2788</span>
<span class="go">-1.6444</span>
<span class="go"> 2.0578</span>
<span class="go">-0.9770</span>
<span class="go">-1.1466</span>
<span class="go"> 1.8726</span>
<span class="go">-0.8000</span>
<span class="go">[torch.FloatTensor of size 10]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="go"> 1.1148</span>
<span class="go"> 2.0537</span>
<span class="go"> 2.9045</span>
<span class="go">-1.2788</span>
<span class="go">-1.6444</span>
<span class="go">-0.0000</span>
<span class="go"> 0.0000</span>
<span class="go"> 0.0000</span>
<span class="go">-0.0000</span>
<span class="go"> 0.0000</span>
<span class="go">[torch.FloatTensor of size 10]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.cumsum">
<code class="descclassname">syft.</code><code class="descname">cumsum</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.cumsum" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the cumulative sum of elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> in the dimension
<code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>.</p>
<p>For example, if <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is a vector of size N, the result will also be
a vector of size N, with elements:
<span class="math">\(y_i = x_1 + x_2 + x_3 + ... + x_i\)</span></p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
dim  (int): the dimension to do the operation over
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.6039</span>
<span class="go">-0.2214</span>
<span class="go">-0.3705</span>
<span class="go">-0.0169</span>
<span class="go"> 1.3415</span>
<span class="go">-0.1230</span>
<span class="go"> 0.9719</span>
<span class="go"> 0.6081</span>
<span class="go">-0.1286</span>
<span class="go"> 1.0947</span>
<span class="go">[torch.FloatTensor of size 10]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="go">-0.6039</span>
<span class="go">-0.8253</span>
<span class="go">-1.1958</span>
<span class="go">-1.2127</span>
<span class="go"> 0.1288</span>
<span class="go"> 0.0058</span>
<span class="go"> 0.9777</span>
<span class="go"> 1.5858</span>
<span class="go"> 1.4572</span>
<span class="go"> 2.5519</span>
<span class="go">[torch.FloatTensor of size 10]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.diag">
<code class="descclassname">syft.</code><code class="descname">diag</code><span class="sig-paren">(</span><em>input</em>, <em>diagonal=0</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.diag" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is a vector (1D Tensor), then returns a 2D square Tensor
with the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> as the diagonal.</li>
<li>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is a matrix (2D Tensor), then returns a 1D Tensor with
the diagonal elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</li>
</ul>
<p>The argument <code class="xref py py-attr docutils literal"><span class="pre">diagonal</span></code> controls which diagonal to consider.</p>
<ul class="simple">
<li><code class="xref py py-attr docutils literal"><span class="pre">diagonal</span></code> = 0, is the main diagonal.</li>
<li><code class="xref py py-attr docutils literal"><span class="pre">diagonal</span></code> &gt; 0, is above the main diagonal.</li>
<li><code class="xref py py-attr docutils literal"><span class="pre">diagonal</span></code> &lt; 0, is below the main diagonal.</li>
</ul>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
diagonal (int, optional): the diagonal to consider
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<p>Get the square matrix where the input vector is the diagonal:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.0480</span>
<span class="go">-2.3405</span>
<span class="go">-1.1138</span>
<span class="go">[torch.FloatTensor of size 3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 1.0480  0.0000  0.0000</span>
<span class="go"> 0.0000 -2.3405  0.0000</span>
<span class="go"> 0.0000  0.0000 -1.1138</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="go"> 0.0000  1.0480  0.0000  0.0000</span>
<span class="go"> 0.0000  0.0000 -2.3405  0.0000</span>
<span class="go"> 0.0000  0.0000  0.0000 -1.1138</span>
<span class="go"> 0.0000  0.0000  0.0000  0.0000</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>
</pre></div>
</div>
<p>Get the k-th diagonal of a given matrix:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-1.5328 -1.3210 -1.5204</span>
<span class="go"> 0.8596  0.0471 -0.2239</span>
<span class="go">-0.6617  0.0146 -1.0817</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="go">-1.5328</span>
<span class="go"> 0.0471</span>
<span class="go">-1.0817</span>
<span class="go">[torch.FloatTensor of size 3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="go">-1.3210</span>
<span class="go">-0.2239</span>
<span class="go">[torch.FloatTensor of size 2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.dist">
<code class="descclassname">syft.</code><code class="descname">dist</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>p=2</em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#syft.dist" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the p-norm of (<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> - <code class="xref py py-attr docutils literal"><span class="pre">other</span></code>)</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> must be
<span class="xref std std-ref">broadcastable</span>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
other (Tensor): the Right-hand-side input <cite>Tensor</cite>
p (float, optional): The norm to be computed.</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 0.2505</span>
<span class="go">-0.4571</span>
<span class="go">-0.3733</span>
<span class="go"> 0.7807</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>

<span class="go"> 0.7782</span>
<span class="go">-0.5185</span>
<span class="go"> 1.4106</span>
<span class="go">-2.4063</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">)</span>
<span class="go">3.302832063224223</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">3.3677282206393286</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="go">inf</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">5.560028076171875</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.div">
<code class="descclassname">syft.</code><code class="descname">div</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.div" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">div</code><span class="sig-paren">(</span><em>input</em>, <em>value</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Divides each element of the input <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> with the scalar <code class="xref py py-attr docutils literal"><span class="pre">value</span></code>
and returns a new resulting tensor.</p>
<p><span class="math">\(out = tensor / value\)</span></p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, <code class="xref py py-attr docutils literal"><span class="pre">value</span></code>
should be a real number, otherwise it should be an integer</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
value (Number): the number to be divided to each element of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.6147</span>
<span class="go">-1.1237</span>
<span class="go">-0.1604</span>
<span class="go">-0.6853</span>
<span class="go"> 0.1063</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="go">-1.2294</span>
<span class="go">-2.2474</span>
<span class="go">-0.3208</span>
<span class="go">-1.3706</span>
<span class="go"> 0.2126</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">div</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Each element of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is divided by each element
of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">other</span></code>. The resulting Tensor is returned. The shapes of
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> must be
<span class="xref std std-ref">broadcastable</span>.</p>
<p><span class="math">\(out_i = input_i / other_i\)</span></p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the numerator <cite>Tensor</cite>
other (Tensor): the denominator <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.1810  0.4017  0.2863 -0.1013</span>
<span class="go"> 0.6183  2.0696  0.9012 -1.5933</span>
<span class="go"> 0.5679  0.4743 -0.0117 -0.1266</span>
<span class="go">-0.1213  0.9629  0.2682  1.5968</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>

<span class="go"> 0.8774  0.7650</span>
<span class="go"> 0.8866  1.4805</span>
<span class="go">-0.6490  1.1172</span>
<span class="go"> 1.4259 -0.8146</span>
<span class="go"> 1.4633 -0.1228</span>
<span class="go"> 0.4643 -0.6029</span>
<span class="go"> 0.3492  1.5270</span>
<span class="go"> 1.6103 -0.6291</span>
<span class="go">[torch.FloatTensor of size 8x2]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="go">-0.2062  0.5251  0.3229 -0.0684</span>
<span class="go">-0.9528  1.8525  0.6320  1.9559</span>
<span class="go"> 0.3881 -3.8625 -0.0253  0.2099</span>
<span class="go">-0.3473  0.6306  0.1666 -2.5381</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.dot">
<code class="descclassname">syft.</code><code class="descname">dot</code><span class="sig-paren">(</span><em>tensor1</em>, <em>tensor2</em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#syft.dot" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the dot product (inner product) of two tensors.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This function does not <span class="xref std std-ref">broadcast</span>.</p>
</div>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
<span class="go">7.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.dsmm">
<code class="descclassname">syft.</code><code class="descname">dsmm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.dsmm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="syft.eig">
<code class="descclassname">syft.</code><code class="descname">eig</code><span class="sig-paren">(</span><em>a</em>, <em>eigenvectors=False</em>, <em>out=None) -&gt; (Tensor</em>, <em>Tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.eig" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the eigenvalues and eigenvectors of a real square matrix.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first docutils">
<dt>a (Tensor): A square matrix for which the eigenvalues and eigenvectors will</dt>
<dd>be computed</dd>
<dt>eigenvectors (bool): <code class="docutils literal"><span class="pre">True</span></code> to compute both eigenvalues and eigenvectors.</dt>
<dd>Otherwise, only eigenvalues will be computed.</dd>
</dl>
<p class="last">out (tuple, optional): Output tensors</p>
</dd>
<dt>Returns:</dt>
<dd><p class="first">(Tensor, Tensor): tuple containing</p>
<blockquote class="last">
<div><ul class="simple">
<li><strong>e</strong> (<em>Tensor</em>): the right eigenvalues of <code class="docutils literal"><span class="pre">a</span></code></li>
<li><dl class="first docutils">
<dt><strong>v</strong> (<em>Tensor</em>): the eigenvectors of <code class="docutils literal"><span class="pre">a</span></code> if <code class="docutils literal"><span class="pre">eigenvectors</span></code></dt>
<dd>is <code class="docutils literal"><span class="pre">True</span></code>; otherwise an empty tensor</dd>
</dl>
</li>
</ul>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="syft.eq">
<code class="descclassname">syft.</code><code class="descname">eq</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.eq" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes element-wise equality</p>
<p>The second argument can be a number or a tensor whose shape is
<span class="xref std std-ref">broadcastable</span> with the first argument.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">input (Tensor): Tensor to compare
other (Tensor or float): Tensor or value to compare
out (Tensor, optional): Output tensor. Must be a <cite>ByteTensor</cite> or the same</p>
<blockquote class="last">
<div>type as <cite>tensor</cite>.</div></blockquote>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>Tensor: a <code class="docutils literal"><span class="pre">torch.ByteTensor</span></code> containing a 1 at each location where the</dt>
<dd>tensors are equal and a 0 at every other location</dd>
</dl>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]))</span>
<span class="go">1  0</span>
<span class="go">0  1</span>
<span class="go">[torch.ByteTensor of size 2x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.equal">
<code class="descclassname">syft.</code><code class="descname">equal</code><span class="sig-paren">(</span><em>tensor1</em>, <em>tensor2</em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#syft.equal" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal"><span class="pre">True</span></code> if two tensors have the same size and elements, <code class="docutils literal"><span class="pre">False</span></code> otherwise.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.erf">
<code class="descclassname">syft.</code><code class="descname">erf</code><span class="sig-paren">(</span><em>tensor</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.erf" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the error function of each element.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">erf</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">]))</span>
<span class="go">torch.FloatTensor([0., -0.8427, 1.])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.erfinv">
<code class="descclassname">syft.</code><code class="descname">erfinv</code><span class="sig-paren">(</span><em>tensor</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.erfinv" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the inverse error function of each element.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">erfinv</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="o">.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]))</span>
<span class="go">torch.FloatTensor([0., 0.4769, -inf])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.exp">
<code class="descclassname">syft.</code><code class="descname">exp</code><span class="sig-paren">(</span><em>tensor</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the exponential of each element.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="p">)]))</span>
<span class="go">torch.FloatTensor([1, 2])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.eye">
<code class="descclassname">syft.</code><code class="descname">eye</code><span class="sig-paren">(</span><em>n</em>, <em>m=None</em>, <em>out=None</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.eye" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>n (int): Number of rows
m (int, optional): Number of columns. If None, defaults to <cite>n</cite>
out (Tensor, optional): Output tensor</dd>
<dt>Returns:</dt>
<dd>Tensor: a 2-D tensor with ones on the diagonal and zeros elsewhere</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="go"> 1  0  0</span>
<span class="go"> 0  1  0</span>
<span class="go"> 0  0  1</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.floor">
<code class="descclassname">syft.</code><code class="descname">floor</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.floor" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the floor of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>,
the largest integer less than or equal to each element.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 1</span>
<span class="go"> 0</span>
<span class="go">-1</span>
<span class="go">-1</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.fmod">
<code class="descclassname">syft.</code><code class="descname">fmod</code><span class="sig-paren">(</span><em>input</em>, <em>divisor</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.fmod" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the element-wise remainder of division.</p>
<p>The dividend and divisor may contain both for integer and floating point
numbers. The remainder has the same sign as the dividend <cite>tensor</cite>.</p>
<p>When <code class="xref py py-attr docutils literal"><span class="pre">divisor</span></code> is a Tensor, the shapes of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and
<code class="xref py py-attr docutils literal"><span class="pre">divisor</span></code> must be <span class="xref std std-ref">broadcastable</span>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">input (Tensor): The dividend
divisor (Tensor or float): The divisor. This may be either a number or a</p>
<blockquote>
<div>tensor of the same shape as the dividend.</div></blockquote>
<p class="last">out (Tensor, optional): Output tensor</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">fmod</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">torch.FloatTensor([-1, -0, -1, 1, 0, 1])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">fmod</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]),</span> <span class="mf">1.5</span><span class="p">)</span>
<span class="go">torch.FloatTensor([1.0, 0.5, 0.0, 1.0, 0.5])</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><code class="xref py py-func docutils literal"><span class="pre">torch.remainder()</span></code>, which computes the element-wise remainder of
division equivalently to Python&#8217;s <cite>%</cite> operator</p>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.frac">
<code class="descclassname">syft.</code><code class="descname">frac</code><span class="sig-paren">(</span><em>tensor</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.frac" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the fractional portion of each element in <cite>tensor</cite>.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">frac</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">])</span>
<span class="go">torch.FloatTensor([0, 0.5, -0.2])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.from_numpy">
<code class="descclassname">syft.</code><code class="descname">from_numpy</code><span class="sig-paren">(</span><em>ndarray</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.from_numpy" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a <code class="xref py py-class docutils literal"><span class="pre">Tensor</span></code> from a <code class="xref py py-class docutils literal"><span class="pre">numpy.ndarray</span></code>.</p>
<p>The returned tensor and <cite>ndarray</cite> share the same memory. Modifications to the
tensor will be reflected in the <cite>ndarray</cite> and vice versa. The returned tensor
is not resizable.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span>
<span class="go">torch.LongTensor([1, 2, 3])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">array([-1,  2,  3])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.gather">
<code class="descclassname">syft.</code><code class="descname">gather</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>index</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.gather" title="Permalink to this definition">¶</a></dt>
<dd><p>Gathers values along an axis specified by <cite>dim</cite>.</p>
<p>For a 3-D tensor the output is specified by:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if dim == 0</span>
<span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if dim == 1</span>
<span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]]</span>  <span class="c1"># if dim == 2</span>
</pre></div>
</div>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is an n-dimensional tensor with size
<span class="math">\((x_0, x_1..., x_{i-1}, x_i, x_{i+1}, ..., x_{n-1})\)</span>
and <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> = i, then <code class="xref py py-attr docutils literal"><span class="pre">index</span></code> must be an n-dimensional tensor with
size <span class="math">\((x_0, x_1, ..., x_{i-1}, y, x_{i+1}, ..., x_{n-1})\)</span> where y &gt;= 1 and
<code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will have the same size as <code class="xref py py-attr docutils literal"><span class="pre">index</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): The source tensor
dim (int): The axis along which to index
index (LongTensor): The indices of elements to gather
out (Tensor, optional): Destination tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]]))</span>
<span class="go"> 1  1</span>
<span class="go"> 4  3</span>
<span class="go">[torch.FloatTensor of size 2x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.ge">
<code class="descclassname">syft.</code><code class="descname">ge</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.ge" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes <cite>tensor &gt;= other</cite> element-wise.</p>
<p>The second argument can be a number or a tensor whose shape is
<span class="xref std std-ref">broadcastable</span> with the first argument.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">input (Tensor): Tensor to compare
other (Tensor or float): Tensor or value to compare
out (Tensor, optional): Output tensor. Must be a <cite>ByteTensor</cite> or the same</p>
<blockquote class="last">
<div>type as <cite>tensor</cite>.</div></blockquote>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>Tensor: a <code class="docutils literal"><span class="pre">torch.ByteTensor</span></code> containing a 1 at each location where</dt>
<dd>comparison is true.</dd>
</dl>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">ge</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]))</span>
<span class="go"> 1  1</span>
<span class="go"> 0  1</span>
<span class="go">[torch.ByteTensor of size 2x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.gels">
<code class="descclassname">syft.</code><code class="descname">gels</code><span class="sig-paren">(</span><em>B</em>, <em>A</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.gels" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the solution to the least squares and least norm problems for a full
rank <span class="math">\(m\)</span> by <span class="math">\(n\)</span> matrix <span class="math">\(A\)</span>.</p>
<p>If <span class="math">\(m &gt;= n\)</span>, <a class="reference internal" href="../index.html#syft.gels" title="syft.gels"><code class="xref py py-func docutils literal"><span class="pre">gels()</span></code></a> solves the least-squares problem:</p>
<div class="math">
\[\begin{array}{ll}
\mbox{minimize} &amp; \|AX-B\|_F.
\end{array}\]</div>
<p>If <span class="math">\(m &lt; n\)</span>, <a class="reference internal" href="../index.html#syft.gels" title="syft.gels"><code class="xref py py-func docutils literal"><span class="pre">gels()</span></code></a> solves the least-norm problem:</p>
<div class="math">
\[\begin{array}{ll}
\mbox{minimize} &amp; \|X\|_F &amp; \mbox{subject to} &amp; AX = B.
\end{array}\]</div>
<p>The first <span class="math">\(n\)</span> rows of the returned matrix <span class="math">\(X\)</span> contains the
solution. The remaining rows contain residual information: the euclidean norm
of each column starting at row <span class="math">\(n\)</span> is the residual for the corresponding
column.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>B (Tensor): The matrix <span class="math">\(B\)</span>
A (Tensor): The <span class="math">\(m\)</span> by <span class="math">\(n\)</span> matrix <span class="math">\(A\)</span>
out (tuple, optional): Optional destination tensor</dd>
<dt>Returns:</dt>
<dd><p class="first">(Tensor, Tensor): tuple containing:</p>
<blockquote class="last">
<div><ul class="simple">
<li><strong>X</strong> (<em>Tensor</em>): the least squares solution</li>
<li><strong>qr</strong> (<em>Tensor</em>): the details of the QR factorization</li>
</ul>
</div></blockquote>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The returned matrices will always be transposed, irrespective of the strides
of the input matrices. That is, they will have stride <cite>(1, m)</cite> instead of
<cite>(m, 1)</cite>.</p>
</div>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">],</span>
<span class="go">                      [ 12, 14],</span>
<span class="go">                      [ 14, 12],</span>
<span class="go">                      [ 16, 16],</span>
<span class="go">                      [ 18, 16]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gels</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span>
<span class="go">2.0000  1.0000</span>
<span class="go">1.0000  1.0000</span>
<span class="go">1.0000  2.0000</span>
<span class="go">[torch.FloatTensor of size 3x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.geqrf">
<code class="descclassname">syft.</code><code class="descname">geqrf</code><span class="sig-paren">(</span><em>input</em>, <em>out=None) -&gt; (Tensor</em>, <em>Tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.geqrf" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a low-level function for calling LAPACK directly.</p>
<p>You&#8217;ll generally want to use <code class="xref py py-func docutils literal"><span class="pre">torch.qr()</span></code> instead.</p>
<p>Computes a QR decomposition of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>, but without constructing
<cite>Q</cite> and <cite>R</cite> as explicit separate matrices.</p>
<p>Rather, this directly calls the underlying LAPACK function <cite>?geqrf</cite>
which produces a sequence of &#8216;elementary reflectors&#8217;.</p>
<p>See <a class="reference external" href="https://software.intel.com/en-us/node/521004">LAPACK documentation</a> for further details.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input matrix
out (tuple, optional): The result tuple of (Tensor, Tensor)</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="syft.ger">
<code class="descclassname">syft.</code><code class="descname">ger</code><span class="sig-paren">(</span><em>vec1</em>, <em>vec2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.ger" title="Permalink to this definition">¶</a></dt>
<dd><p>Outer product of <code class="xref py py-attr docutils literal"><span class="pre">vec1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">vec2</span></code>.
If <code class="xref py py-attr docutils literal"><span class="pre">vec1</span></code> is a vector of size <cite>n</cite> and <code class="xref py py-attr docutils literal"><span class="pre">vec2</span></code> is a vector of
size <cite>m</cite>, then <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> must be a matrix of size <cite>n x m</cite>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This function does not <span class="xref std std-ref">broadcast</span>.</p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd>vec1 (Tensor): 1D input vector
vec2 (Tensor): 1D input vector
out (Tensor, optional): optional output matrix</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">v1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">ger</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span>

<span class="go">  1   2   3</span>
<span class="go">  2   4   6</span>
<span class="go">  3   6   9</span>
<span class="go">  4   8  12</span>
<span class="go">[torch.FloatTensor of size 4x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.gesv">
<code class="descclassname">syft.</code><code class="descname">gesv</code><span class="sig-paren">(</span><em>B</em>, <em>A</em>, <em>out=None) -&gt; (Tensor</em>, <em>Tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.gesv" title="Permalink to this definition">¶</a></dt>
<dd><p><cite>X, LU = torch.gesv(B, A)</cite> returns the solution to the system of linear
equations represented by <span class="math">\(AX = B\)</span></p>
<p><cite>LU</cite> contains <cite>L</cite> and <cite>U</cite> factors for LU factorization of <cite>A</cite>.</p>
<p><code class="xref py py-attr docutils literal"><span class="pre">A</span></code> has to be a square and non-singular matrix (2D Tensor).</p>
<p>If <cite>A</cite> is an <cite>m x m</cite> matrix and <cite>B</cite> is <cite>m x k</cite>,
the result <cite>LU</cite> is <cite>m x m</cite> and <cite>X</cite> is <cite>m x k</cite> .</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Irrespective of the original strides, the returned matrices
<cite>X</cite> and <cite>LU</cite> will be transposed, i.e. with strides <cite>(1, m)</cite>
instead of <cite>(m, 1)</cite>.</p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd>B (Tensor): input matrix of <cite>m x k</cite> dimensions
A (Tensor): input square matrix of <cite>m x m</cite> dimensions
out (Tensor, optional): optional output matrix</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">6.80</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.11</span><span class="p">,</span>  <span class="mf">5.66</span><span class="p">,</span>  <span class="mf">5.97</span><span class="p">,</span>  <span class="mf">8.23</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="o">-</span><span class="mf">6.05</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.30</span><span class="p">,</span>  <span class="mf">5.36</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.44</span><span class="p">,</span>  <span class="mf">1.08</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="o">-</span><span class="mf">0.45</span><span class="p">,</span>  <span class="mf">2.58</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.70</span><span class="p">,</span>  <span class="mf">0.27</span><span class="p">,</span>  <span class="mf">9.04</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mf">8.32</span><span class="p">,</span>  <span class="mf">2.71</span><span class="p">,</span>  <span class="mf">4.35</span><span class="p">,</span>  <span class="o">-</span><span class="mf">7.17</span><span class="p">,</span>  <span class="mf">2.14</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="o">-</span><span class="mf">9.67</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.14</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.26</span><span class="p">,</span>  <span class="mf">6.08</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.87</span><span class="p">]])</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">4.02</span><span class="p">,</span>  <span class="mf">6.19</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.22</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.57</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.03</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="o">-</span><span class="mf">1.56</span><span class="p">,</span>  <span class="mf">4.00</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.67</span><span class="p">,</span>  <span class="mf">1.75</span><span class="p">,</span>  <span class="mf">2.86</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mf">9.81</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.09</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.57</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.61</span><span class="p">,</span>  <span class="mf">8.99</span><span class="p">]])</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">LU</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gesv</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">X</span><span class="p">))</span>
<span class="go">9.250057093890353e-06</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.get_num_threads">
<code class="descclassname">syft.</code><code class="descname">get_num_threads</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#syft.get_num_threads" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the number of OpenMP threads used for parallelizing CPU operations</p>
</dd></dl>

<dl class="function">
<dt id="syft.gt">
<code class="descclassname">syft.</code><code class="descname">gt</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.gt" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes <cite>tensor &gt; other</cite> element-wise.</p>
<p>The second argument can be a number or a tensor whose shape is
<span class="xref std std-ref">broadcastable</span> with the first argument.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">input (Tensor): Tensor to compare
other (Tensor or float): Tensor or value to compare
out (Tensor, optional): Output tensor. Must be a <cite>ByteTensor</cite> or the same</p>
<blockquote class="last">
<div>type as <cite>tensor</cite>.</div></blockquote>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>Tensor: a <code class="docutils literal"><span class="pre">torch.ByteTensor</span></code> containing a 1 at each location where</dt>
<dd>comparison is true.</dd>
</dl>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]))</span>
<span class="go"> 0  1</span>
<span class="go"> 0  0</span>
<span class="go">[torch.ByteTensor of size 2x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.histc">
<code class="descclassname">syft.</code><code class="descname">histc</code><span class="sig-paren">(</span><em>input</em>, <em>bins=100</em>, <em>min=0</em>, <em>max=0</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.histc" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the histogram of a tensor.</p>
<p>The elements are sorted into equal width bins between <cite>min</cite> and <cite>max</cite>. If <cite>min</cite>
and <cite>max</cite> are both zero, the minimum and maximum values of the data are used.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): Input data
bins (int): Number of histogram bins
min (int): Lower end of the range (inclusive)
max (int): Upper end of the range (inclusive)
out (Tensor, optional): Output argument</dd>
<dt>Returns:</dt>
<dd>Tensor: the histogram</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">histc</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="go">FloatTensor([0, 2, 1, 0])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.hsmm">
<code class="descclassname">syft.</code><code class="descname">hsmm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.hsmm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="syft.index_select">
<code class="descclassname">syft.</code><code class="descname">index_select</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>index</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.index_select" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> which indexes the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> <cite>Tensor</cite> along dimension
<code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> using the entries in <code class="xref py py-attr docutils literal"><span class="pre">index</span></code> which is a <cite>LongTensor</cite>.</p>
<p>The returned <cite>Tensor</cite> has the same number of dimensions as
the original <cite>Tensor</cite>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The returned <cite>Tensor</cite> does <strong>not</strong> use the same storage as
the original <cite>Tensor</cite></p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): Input data
dim (int): the dimension in which we index
index (LongTensor): the 1D tensor containing the indices to index
out (Tensor, optional): Output argument</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 1.2045  2.4084  0.4001  1.1372</span>
<span class="go"> 0.5596  1.5677  0.6219 -0.7954</span>
<span class="go"> 1.3635 -1.2313 -0.5414 -1.8478</span>
<span class="go">[torch.FloatTensor of size 3x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>

<span class="go"> 1.2045  2.4084  0.4001  1.1372</span>
<span class="go"> 1.3635 -1.2313 -0.5414 -1.8478</span>
<span class="go">[torch.FloatTensor of size 2x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>

<span class="go"> 1.2045  0.4001</span>
<span class="go"> 0.5596  0.6219</span>
<span class="go"> 1.3635 -0.5414</span>
<span class="go">[torch.FloatTensor of size 3x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.inverse">
<code class="descclassname">syft.</code><code class="descname">inverse</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.inverse" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes the inverse of the square matrix <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Irrespective of the original strides, the returned matrix will be
transposed, i.e. with strides <cite>(1, m)</cite> instead of <cite>(m, 1)</cite></p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input 2D square <cite>Tensor</cite>
out (Tensor, optional): the optional output <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 0.7800  0.2267  0.7855  0.9479  0.5914  0.7119  0.4437  0.9131  0.1289  0.1982</span>
<span class="go"> 0.0045  0.0425  0.2229  0.4626  0.6210  0.0207  0.6338  0.7067  0.6381  0.8196</span>
<span class="go"> 0.8350  0.7810  0.8526  0.9364  0.7504  0.2737  0.0694  0.5899  0.8516  0.3883</span>
<span class="go"> 0.6280  0.6016  0.5357  0.2936  0.7827  0.2772  0.0744  0.2627  0.6326  0.9153</span>
<span class="go"> 0.7897  0.0226  0.3102  0.0198  0.9415  0.9896  0.3528  0.9397  0.2074  0.6980</span>
<span class="go"> 0.5235  0.6119  0.6522  0.3399  0.3205  0.5555  0.8454  0.3792  0.4927  0.6086</span>
<span class="go"> 0.1048  0.0328  0.5734  0.6318  0.9802  0.4458  0.0979  0.3320  0.3701  0.0909</span>
<span class="go"> 0.2616  0.3485  0.4370  0.5620  0.5291  0.8295  0.7693  0.1807  0.0650  0.8497</span>
<span class="go"> 0.1655  0.2192  0.6913  0.0093  0.0178  0.3064  0.6715  0.5101  0.2561  0.3396</span>
<span class="go"> 0.4370  0.4695  0.8333  0.1180  0.4266  0.4161  0.0699  0.4263  0.8865  0.2578</span>
<span class="go">[torch.FloatTensor of size 10x10]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span>

<span class="go"> 1.0000  0.0000  0.0000 -0.0000  0.0000  0.0000  0.0000  0.0000 -0.0000 -0.0000</span>
<span class="go"> 0.0000  1.0000 -0.0000  0.0000  0.0000  0.0000 -0.0000 -0.0000 -0.0000 -0.0000</span>
<span class="go"> 0.0000  0.0000  1.0000 -0.0000 -0.0000  0.0000  0.0000  0.0000 -0.0000 -0.0000</span>
<span class="go"> 0.0000  0.0000  0.0000  1.0000  0.0000  0.0000  0.0000 -0.0000 -0.0000  0.0000</span>
<span class="go"> 0.0000  0.0000 -0.0000 -0.0000  1.0000  0.0000  0.0000 -0.0000 -0.0000 -0.0000</span>
<span class="go"> 0.0000  0.0000  0.0000 -0.0000  0.0000  1.0000 -0.0000 -0.0000 -0.0000 -0.0000</span>
<span class="go"> 0.0000  0.0000  0.0000 -0.0000  0.0000  0.0000  1.0000  0.0000 -0.0000  0.0000</span>
<span class="go"> 0.0000  0.0000 -0.0000 -0.0000  0.0000  0.0000 -0.0000  1.0000 -0.0000  0.0000</span>
<span class="go">-0.0000  0.0000 -0.0000 -0.0000  0.0000  0.0000 -0.0000 -0.0000  1.0000 -0.0000</span>
<span class="go">-0.0000  0.0000 -0.0000 -0.0000 -0.0000  0.0000 -0.0000 -0.0000  0.0000  1.0000</span>
<span class="go">[torch.FloatTensor of size 10x10]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">)))</span> <span class="c1"># Max nonzero</span>
<span class="go">5.096662789583206e-07</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.kthvalue">
<code class="descclassname">syft.</code><code class="descname">kthvalue</code><span class="sig-paren">(</span><em>input</em>, <em>k</em>, <em>dim=None</em>, <em>keepdim=False</em>, <em>out=None) -&gt; (Tensor</em>, <em>LongTensor</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.kthvalue" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the <code class="xref py py-attr docutils literal"><span class="pre">k</span></code> th smallest element of the given <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor
along a given dimension.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is not given, the last dimension of the <cite>input</cite> is chosen.</p>
<p>A tuple of <cite>(values, indices)</cite> is returned, where the <cite>indices</cite> is the indices
of the kth-smallest element in the original <cite>input</cite> Tensor in dimension <cite>dim</cite>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is <code class="docutils literal"><span class="pre">True</span></code>, both the <code class="xref py py-attr docutils literal"><span class="pre">values</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">indices</span></code> Tensors
are the same size as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>, except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where
they are of size 1. Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed
(see <code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code>), resulting in both the <code class="xref py py-attr docutils literal"><span class="pre">values</span></code> and
<code class="xref py py-attr docutils literal"><span class="pre">indices</span></code> Tensors having 1 fewer dimension than the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">input (Tensor): the input <cite>Tensor</cite>
k (int): k for the k-th smallest element
dim (int, optional): The dimension to find the kth value along
keepdim (bool): whether the output Tensors have <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not
out (tuple, optional): The output tuple of (Tensor, LongTensor)</p>
<blockquote class="last">
<div>can be optionally given to be used as output buffers</div></blockquote>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go"> 5</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">kthvalue</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="go">(</span>
<span class="go"> 4</span>
<span class="go">[torch.FloatTensor of size 1]</span>
<span class="go">,</span>
<span class="go"> 3</span>
<span class="go">[torch.LongTensor of size 1]</span>
<span class="go">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span><span class="o">.</span><span class="n">resize_</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go">1  2  3</span>
<span class="go">4  5  6</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">kthvalue</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
<span class="go">(</span>
<span class="go">4  5  6</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>
<span class="go">       ,</span>
<span class="go">1  1  1</span>
<span class="go">[torch.LongTensor of size 1x3]</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.le">
<code class="descclassname">syft.</code><code class="descname">le</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.le" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes <cite>tensor &lt;= other</cite> element-wise.</p>
<p>The second argument can be a number or a tensor whose shape is
<span class="xref std std-ref">broadcastable</span> with the first argument.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">input (Tensor): Tensor to compare
other (Tensor or float): Tensor or value to compare
out (Tensor, optional): Output tensor. Must be a <cite>ByteTensor</cite> or the same</p>
<blockquote class="last">
<div>type as <cite>tensor</cite>.</div></blockquote>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>Tensor: a <code class="docutils literal"><span class="pre">torch.ByteTensor</span></code> containing a 1 at each location where</dt>
<dd>comparison is true.</dd>
</dl>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">le</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]))</span>
<span class="go"> 1  0</span>
<span class="go"> 1  1</span>
<span class="go">[torch.ByteTensor of size 2x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.lerp">
<code class="descclassname">syft.</code><code class="descname">lerp</code><span class="sig-paren">(</span><em>start</em>, <em>end</em>, <em>weight</em>, <em>out=None</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.lerp" title="Permalink to this definition">¶</a></dt>
<dd><p>Does a linear interpolation of two tensors <code class="xref py py-attr docutils literal"><span class="pre">start</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">end</span></code> based
on a scalar <code class="xref py py-attr docutils literal"><span class="pre">weight</span></code>: and returns the resulting <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> Tensor.</p>
<p><span class="math">\(out_i = start_i + weight * (end_i - start_i)\)</span></p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">start</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">end</span></code> must be
<span class="xref std std-ref">broadcastable</span>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>start (Tensor): the <cite>Tensor</cite> with the starting points
end (Tensor): the <cite>Tensor</cite> with the ending points
weight (float): the weight for the interpolation formula
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">start</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">end</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">start</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">end</span>

<span class="go"> 10</span>
<span class="go"> 10</span>
<span class="go"> 10</span>
<span class="go"> 10</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">lerp</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="go"> 5.5000</span>
<span class="go"> 6.0000</span>
<span class="go"> 6.5000</span>
<span class="go"> 7.0000</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.lgamma">
<code class="descclassname">syft.</code><code class="descname">lgamma</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.lgamma" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="syft.linspace">
<code class="descclassname">syft.</code><code class="descname">linspace</code><span class="sig-paren">(</span><em>start</em>, <em>end</em>, <em>steps=100</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.linspace" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a one-dimensional Tensor of <code class="xref py py-attr docutils literal"><span class="pre">steps</span></code>
equally spaced points between <code class="xref py py-attr docutils literal"><span class="pre">start</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">end</span></code></p>
<p>The output tensor is 1D of size <code class="xref py py-attr docutils literal"><span class="pre">steps</span></code></p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">start (float): The starting value for the set of points
end (float): The ending value for the set of points
steps (int): Number of points to sample between <code class="xref py py-attr docutils literal"><span class="pre">start</span></code></p>
<blockquote>
<div>and <code class="xref py py-attr docutils literal"><span class="pre">end</span></code></div></blockquote>
<p class="last">out (Tensor, optional): The result <cite>Tensor</cite></p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="go">  3.0000</span>
<span class="go">  4.7500</span>
<span class="go">  6.5000</span>
<span class="go">  8.2500</span>
<span class="go"> 10.0000</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="go">-10</span>
<span class="go"> -5</span>
<span class="go">  0</span>
<span class="go">  5</span>
<span class="go"> 10</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="go">-10</span>
<span class="go"> -5</span>
<span class="go">  0</span>
<span class="go">  5</span>
<span class="go"> 10</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.log">
<code class="descclassname">syft.</code><code class="descname">log</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.log" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the natural logarithm of the elements
of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.4183</span>
<span class="go"> 0.3722</span>
<span class="go">-0.3091</span>
<span class="go"> 0.4149</span>
<span class="go"> 0.5857</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go">    nan</span>
<span class="go">-0.9883</span>
<span class="go">    nan</span>
<span class="go">-0.8797</span>
<span class="go">-0.5349</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.log1p">
<code class="descclassname">syft.</code><code class="descname">log1p</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.log1p" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the natural logarithm of (1 + <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>).</p>
<p><span class="math">\(y_i = log(x_i + 1)\)</span></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This function is more accurate than <code class="xref py py-func docutils literal"><span class="pre">torch.log()</span></code> for small
values of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code></p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.4183</span>
<span class="go"> 0.3722</span>
<span class="go">-0.3091</span>
<span class="go"> 0.4149</span>
<span class="go"> 0.5857</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go">-0.5418</span>
<span class="go"> 0.3164</span>
<span class="go">-0.3697</span>
<span class="go"> 0.3471</span>
<span class="go"> 0.4611</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.logspace">
<code class="descclassname">syft.</code><code class="descname">logspace</code><span class="sig-paren">(</span><em>start</em>, <em>end</em>, <em>steps=100</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.logspace" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a one-dimensional Tensor of <code class="xref py py-attr docutils literal"><span class="pre">steps</span></code> points
logarithmically spaced between <span class="math">\(10^{start}\)</span> and <span class="math">\(10^{end}\)</span></p>
<p>The output is a 1D tensor of size <code class="xref py py-attr docutils literal"><span class="pre">steps</span></code></p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">start (float): The starting value for the set of points
end (float): The ending value for the set of points
steps (int): Number of points to sample between</p>
<blockquote>
<div><code class="xref py py-attr docutils literal"><span class="pre">start</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">end</span></code></div></blockquote>
<p class="last">out (Tensor, optional): The result <cite>Tensor</cite></p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="n">start</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="go"> 1.0000e-10</span>
<span class="go"> 1.0000e-05</span>
<span class="go"> 1.0000e+00</span>
<span class="go"> 1.0000e+05</span>
<span class="go"> 1.0000e+10</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="go">  1.2589</span>
<span class="go">  2.1135</span>
<span class="go">  3.5481</span>
<span class="go">  5.9566</span>
<span class="go"> 10.0000</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.lt">
<code class="descclassname">syft.</code><code class="descname">lt</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.lt" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes <cite>tensor &lt; other</cite> element-wise.</p>
<p>The second argument can be a number or a tensor whose shape is
<span class="xref std std-ref">broadcastable</span> with the first argument.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">input (Tensor): Tensor to compare
other (Tensor or float): Tensor or value to compare
out (Tensor, optional): Output tensor. Must be a <cite>ByteTensor</cite> or</p>
<blockquote class="last">
<div>the same type as <cite>tensor</cite>.</div></blockquote>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>Tensor: a <code class="docutils literal"><span class="pre">torch.ByteTensor</span></code> containing a 1 at each location where</dt>
<dd>comparison is true.</dd>
</dl>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">lt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]))</span>
<span class="go"> 0  0</span>
<span class="go"> 1  0</span>
<span class="go">[torch.ByteTensor of size 2x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.masked_select">
<code class="descclassname">syft.</code><code class="descname">masked_select</code><span class="sig-paren">(</span><em>input</em>, <em>mask</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.masked_select" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new 1D <cite>Tensor</cite> which indexes the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> <cite>Tensor</cite> according to
the binary mask <code class="xref py py-attr docutils literal"><span class="pre">mask</span></code> which is a <cite>ByteTensor</cite>.</p>
<p>The shapes of the <code class="xref py py-attr docutils literal"><span class="pre">mask</span></code> tensor and the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> tensor don&#8217;t need
to match, but they must be <span class="xref std std-ref">broadcastable</span>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The returned <cite>Tensor</cite> does <strong>not</strong> use the same storage
as the original <cite>Tensor</cite></p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): Input data
mask  (ByteTensor): the tensor containing the binary mask to index with
out (Tensor, optional): Output argument</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 1.2045  2.4084  0.4001  1.1372</span>
<span class="go"> 0.5596  1.5677  0.6219 -0.7954</span>
<span class="go"> 1.3635 -1.2313 -0.5414 -1.8478</span>
<span class="go">[torch.FloatTensor of size 3x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">ge</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span>

<span class="go"> 1  1  0  1</span>
<span class="go"> 1  1  1  0</span>
<span class="go"> 1  0  0  0</span>
<span class="go">[torch.ByteTensor of size 3x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

<span class="go"> 1.2045</span>
<span class="go"> 2.4084</span>
<span class="go"> 1.1372</span>
<span class="go"> 0.5596</span>
<span class="go"> 1.5677</span>
<span class="go"> 0.6219</span>
<span class="go"> 1.3635</span>
<span class="go">[torch.FloatTensor of size 7]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.max">
<code class="descclassname">syft.</code><code class="descname">max</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.max" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">max</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the maximum value of all elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.4729 -0.2266 -0.2085</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">0.4729</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">max</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>keepdim=False</em>, <em>out=None) -&gt; (Tensor</em>, <em>LongTensor</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Returns the maximum value of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>. The second return value is the index location of each
maximum value found (argmax).</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is <code class="docutils literal"><span class="pre">True</span></code>, the output Tensors are of the same size
as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where they are of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code>), resulting
in the output Tensors having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
dim (int): the dimension to reduce
keepdim (bool): whether the output Tensors have <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not
out (tuple, optional): the result tuple of two output Tensors (max, max_indices)</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;</span> <span class="n">a</span>

<span class="mf">0.0692</span>  <span class="mf">0.3142</span>  <span class="mf">1.2513</span> <span class="o">-</span><span class="mf">0.5428</span>
<span class="mf">0.9288</span>  <span class="mf">0.8552</span> <span class="o">-</span><span class="mf">0.2073</span>  <span class="mf">0.6409</span>
<span class="mf">1.0695</span> <span class="o">-</span><span class="mf">0.0101</span> <span class="o">-</span><span class="mf">2.4507</span> <span class="o">-</span><span class="mf">1.2230</span>
<span class="mf">0.7426</span> <span class="o">-</span><span class="mf">0.7666</span>  <span class="mf">0.4862</span> <span class="o">-</span><span class="mf">0.6628</span>
<span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="n">x4</span><span class="p">]</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">(</span>
 <span class="mf">1.2513</span>
 <span class="mf">0.9288</span>
 <span class="mf">1.0695</span>
 <span class="mf">0.7426</span>
<span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="p">]</span>
<span class="p">,</span>
 <span class="mi">2</span>
 <span class="mi">0</span>
 <span class="mi">0</span>
 <span class="mi">0</span>
<span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">max</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Each element of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is compared with the corresponding
element of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> and an element-wise <cite>max</cite> is taken.</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> don&#8217;t need to match,
but they must be <span class="xref std std-ref">broadcastable</span>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">When the shapes do not match, the shape of the returned output tensor
follows the <span class="xref std std-ref">broadcasting rules</span>.</p>
</div>
<p><span class="math">\(out_i = max(tensor_i, other_i)\)</span></p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
other (Tensor): the second input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>

<span class="go"> 1.0067</span>
<span class="go">-0.8010</span>
<span class="go"> 0.6258</span>
<span class="go"> 0.3627</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go"> 0.6258</span>
<span class="go"> 0.3627</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.mean">
<code class="descclassname">syft.</code><code class="descname">mean</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.mean" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">mean</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the mean value of all elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.2946 -0.9143  2.1809</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">0.32398951053619385</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">mean</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>keepdim=False</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Returns the mean value of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is <code class="docutils literal"><span class="pre">True</span></code>, the output Tensor is of the same size
as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where it is of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code>), resulting in the
output Tensor having 1 fewer dimension.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">input (Tensor): the input <cite>Tensor</cite>
dim (int): the dimension to reduce
keepdim (bool, optional): whether the output tensor has <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code></p>
<blockquote>
<div>retained or not</div></blockquote>
<p class="last">out (Tensor): the result Tensor</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-1.2738 -0.3058  0.1230 -1.9615</span>
<span class="go"> 0.8771 -0.5430 -0.9233  0.9879</span>
<span class="go"> 1.4107  0.0317 -0.6823  0.2255</span>
<span class="go">-1.3854  0.4953 -0.2160  0.2435</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="go">-0.8545</span>
<span class="go"> 0.0997</span>
<span class="go"> 0.2464</span>
<span class="go">-0.2157</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

<span class="go">-0.8545</span>
<span class="go"> 0.0997</span>
<span class="go"> 0.2464</span>
<span class="go">-0.2157</span>
<span class="go">[torch.FloatTensor of size 4x1]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.median">
<code class="descclassname">syft.</code><code class="descname">median</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.median" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">median</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the median value of all elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.4729 -0.2266 -0.2085</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">-0.2085</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">median</code><span class="sig-paren">(</span><em>input</em>, <em>dim=-1</em>, <em>keepdim=False</em>, <em>values=None</em>, <em>indices=None) -&gt; (Tensor</em>, <em>LongTensor</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Returns the median value of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>. Also returns the index location of the median value
as a <cite>LongTensor</cite>.</p>
<p>By default, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is the last dimension of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is <code class="docutils literal"><span class="pre">True</span></code>, the output Tensors are of the same size
as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where they are of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code>), resulting in
the outputs Tensor having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
dim (int): the dimension to reduce
keepdim (bool): whether the output Tensors have <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not
values (Tensor, optional): the result Tensor
indices (Tensor, optional): the result index Tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> -0.6891 -0.6662</span>
<span class="go"> 0.2697  0.7412</span>
<span class="go"> 0.5254 -0.7402</span>
<span class="go"> 0.5528 -0.2399</span>
<span class="go">[torch.FloatTensor of size 4x2]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.4056 -0.3372  1.0973 -2.4884  0.4334</span>
<span class="go"> 2.1336  0.3841  0.1404 -0.1821 -0.7646</span>
<span class="go">-0.2403  1.3975 -2.0068  0.1298  0.0212</span>
<span class="go">-1.5371 -0.7257 -0.4871 -0.2359 -1.1724</span>
<span class="go">[torch.FloatTensor of size 4x5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">(</span>
<span class="go"> 0.4056</span>
<span class="go"> 0.1404</span>
<span class="go"> 0.0212</span>
<span class="go">-0.7257</span>
<span class="go">[torch.FloatTensor of size 4]</span>
<span class="go">,</span>
<span class="go"> 0</span>
<span class="go"> 2</span>
<span class="go"> 4</span>
<span class="go"> 1</span>
<span class="go">[torch.LongTensor of size 4]</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.min">
<code class="descclassname">syft.</code><code class="descname">min</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.min" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">min</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the minimum value of all elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.4729 -0.2266 -0.2085</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">-0.22663167119026184</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">min</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>keepdim=False</em>, <em>out=None) -&gt; (Tensor</em>, <em>LongTensor</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Returns the minimum value of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>. The second return value is the index location of each
minimum value found (argmin).</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is <code class="docutils literal"><span class="pre">True</span></code>, the output Tensors are of the same size as
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where they are of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code>), resulting in
the output Tensors having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
dim (int): the dimension to reduce
keepdim (bool): whether the output tensors have <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not
out (tuple, optional): the result tuple of two output Tensors (min, min_indices)</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;</span> <span class="n">a</span>

<span class="mf">0.0692</span>  <span class="mf">0.3142</span>  <span class="mf">1.2513</span> <span class="o">-</span><span class="mf">0.5428</span>
<span class="mf">0.9288</span>  <span class="mf">0.8552</span> <span class="o">-</span><span class="mf">0.2073</span>  <span class="mf">0.6409</span>
<span class="mf">1.0695</span> <span class="o">-</span><span class="mf">0.0101</span> <span class="o">-</span><span class="mf">2.4507</span> <span class="o">-</span><span class="mf">1.2230</span>
<span class="mf">0.7426</span> <span class="o">-</span><span class="mf">0.7666</span>  <span class="mf">0.4862</span> <span class="o">-</span><span class="mf">0.6628</span>
<span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="n">x4</span><span class="p">]</span>

<span class="o">&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="mf">0.5428</span>
<span class="mf">0.2073</span>
<span class="mf">2.4507</span>
<span class="mf">0.7666</span>
<span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="p">]</span>

<span class="mi">3</span>
<span class="mi">2</span>
<span class="mi">2</span>
<span class="mi">1</span>
<span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="p">]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">min</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Each element of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is compared with the corresponding
element of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> and an element-wise <cite>min</cite> is taken.
The resulting Tensor is returned.</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> don&#8217;t need to match,
but they must be <span class="xref std std-ref">broadcastable</span>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">When the shapes do not match, the shape of the returned output tensor
follows the <span class="xref std std-ref">broadcasting rules</span>.</p>
</div>
<p><span class="math">\(out_i = min(tensor_i, other_i)\)</span></p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
other (Tensor): the second input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>

<span class="go"> 1.0067</span>
<span class="go">-0.8010</span>
<span class="go"> 0.6258</span>
<span class="go"> 0.3627</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="go"> 1.0067</span>
<span class="go">-0.8010</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.mm">
<code class="descclassname">syft.</code><code class="descname">mm</code><span class="sig-paren">(</span><em>mat1</em>, <em>mat2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.mm" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a matrix multiplication of the matrices <code class="xref py py-attr docutils literal"><span class="pre">mat1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">mat2</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">mat1</span></code> is a <cite>n x m</cite> Tensor, <code class="xref py py-attr docutils literal"><span class="pre">mat2</span></code> is a <cite>m x p</cite> Tensor,
<code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will be a <cite>n x p</cite> Tensor.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This function does not <span class="xref std std-ref">broadcast</span>.
For broadcasting matrix products, see <code class="xref py py-func docutils literal"><span class="pre">torch.matmul()</span></code>.</p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd>mat1 (Tensor): First matrix to be multiplied
mat2 (Tensor): Second matrix to be multiplied
out (Tensor, optional): Output tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mat1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mat2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">)</span>
<span class="go"> 0.0519 -0.3304  1.2232</span>
<span class="go"> 4.3910 -5.1498  2.7571</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.mode">
<code class="descclassname">syft.</code><code class="descname">mode</code><span class="sig-paren">(</span><em>input</em>, <em>dim=-1</em>, <em>keepdim=False</em>, <em>values=None</em>, <em>indices=None) -&gt; (Tensor</em>, <em>LongTensor</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.mode" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the mode value of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>. Also returns the index location of the mode value
as a <cite>LongTensor</cite>.</p>
<p>By default, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is the last dimension of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is <code class="docutils literal"><span class="pre">True</span></code>, the output Tensors are of the same size as
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where they are of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code>), resulting
in the output Tensors having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This function is not defined for <code class="docutils literal"><span class="pre">torch.cuda.Tensor</span></code> yet.</p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
dim (int): the dimension to reduce
keepdim (bool): whether the output tensors have <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not
values (Tensor, optional): the result Tensor
indices (Tensor, optional): the result index Tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> -0.6891 -0.6662</span>
<span class="go"> 0.2697  0.7412</span>
<span class="go"> 0.5254 -0.7402</span>
<span class="go"> 0.5528 -0.2399</span>
<span class="go">[torch.FloatTensor of size 4x2]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.4056 -0.3372  1.0973 -2.4884  0.4334</span>
<span class="go"> 2.1336  0.3841  0.1404 -0.1821 -0.7646</span>
<span class="go">-0.2403  1.3975 -2.0068  0.1298  0.0212</span>
<span class="go">-1.5371 -0.7257 -0.4871 -0.2359 -1.1724</span>
<span class="go">[torch.FloatTensor of size 4x5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">(</span>
<span class="go">-2.4884</span>
<span class="go">-0.7646</span>
<span class="go">-2.0068</span>
<span class="go">-1.5371</span>
<span class="go">[torch.FloatTensor of size 4]</span>
<span class="go">,</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go"> 2</span>
<span class="go"> 0</span>
<span class="go">[torch.LongTensor of size 4]</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.mul">
<code class="descclassname">syft.</code><code class="descname">mul</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.mul" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">mul</code><span class="sig-paren">(</span><em>input</em>, <em>value</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Multiplies each element of the input <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> with the scalar
<code class="xref py py-attr docutils literal"><span class="pre">value</span></code> and returns a new resulting tensor.</p>
<p><span class="math">\(out = tensor * value\)</span></p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, <code class="xref py py-attr docutils literal"><span class="pre">value</span></code>
should be a real number, otherwise it should be an integer</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
value (Number): the number to be multiplied to each element of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.9374</span>
<span class="go">-0.5254</span>
<span class="go">-0.6069</span>
<span class="go">[torch.FloatTensor of size 3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="go">-93.7411</span>
<span class="go">-52.5374</span>
<span class="go">-60.6908</span>
<span class="go">[torch.FloatTensor of size 3]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">mul</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Each element of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is multiplied by each element of the
Tensor <code class="xref py py-attr docutils literal"><span class="pre">other</span></code>. The resulting Tensor is returned.</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> must be
<span class="xref std std-ref">broadcastable</span>.</p>
<p><span class="math">\(out_i = input_i * other_i\)</span></p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the first multiplicand <cite>Tensor</cite>
other (Tensor): the second multiplicand <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.7280  0.0598 -1.4327 -0.5825</span>
<span class="go">-0.1427 -0.0690  0.0821 -0.3270</span>
<span class="go">-0.9241  0.5110  0.4070 -1.1188</span>
<span class="go">-0.8308  0.7426 -0.6240 -1.1582</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>

<span class="go"> 0.0430 -1.0775  0.6015  1.1647 -0.6549  0.0308 -0.1670  1.0742</span>
<span class="go">-1.2593  0.0292 -0.0849  0.4530  1.2404 -0.4659 -0.1840  0.5974</span>
<span class="go">[torch.FloatTensor of size 2x8]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="go">-0.0313 -0.0645 -0.8618 -0.6784</span>
<span class="go"> 0.0934 -0.0021 -0.0137 -0.3513</span>
<span class="go"> 1.1638  0.0149 -0.0346 -0.5068</span>
<span class="go">-1.0304 -0.3460  0.1148 -0.6919</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.multinomial">
<code class="descclassname">syft.</code><code class="descname">multinomial</code><span class="sig-paren">(</span><em>input</em>, <em>num_samples</em>, <em>replacement=False</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; LongTensor<a class="headerlink" href="#syft.multinomial" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a Tensor where each row
contains <code class="xref py py-attr docutils literal"><span class="pre">num_samples</span></code> indices sampled from the multinomial probability
distribution located in the corresponding row of Tensor <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The rows of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> do not need to sum to one (in which case we use
the values as weights), but must be non-negative and have a non-zero sum.</p>
</div>
<p>Indices are ordered from left to right according to when each was sampled
(first samples are placed in first column).</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is a vector, <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> is a vector of size <cite>num_samples</cite>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is a matrix with <cite>m</cite> rows, <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> is an matrix of shape
<cite>m × n</cite>.</p>
<p>If replacement is <code class="docutils literal"><span class="pre">True</span></code>, samples are drawn with replacement.</p>
<p>If not, they are drawn without replacement, which means that when a
sample index is drawn for a row, it cannot be drawn again for that row.</p>
<p>This implies the constraint that <code class="xref py py-attr docutils literal"><span class="pre">num_samples</span></code> must be lower than
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> length (or number of columns of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> if it is a matrix).</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): Tensor containing probabilities
num_samples (int): number of samples to draw
replacement (bool, optional): Whether to draw with replacement or not
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span> <span class="c1"># create a Tensor of weights</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 0</span>
<span class="go"> 0</span>
<span class="go">[torch.LongTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go">[torch.LongTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.mv">
<code class="descclassname">syft.</code><code class="descname">mv</code><span class="sig-paren">(</span><em>mat</em>, <em>vec</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.mv" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a matrix-vector product of the matrix <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> and the vector
<code class="xref py py-attr docutils literal"><span class="pre">vec</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> is a <cite>n x m</cite> Tensor, <code class="xref py py-attr docutils literal"><span class="pre">vec</span></code> is a 1D Tensor of size <cite>m</cite>,
<code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will be 1D of size <cite>n</cite>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This function does not <span class="xref std std-ref">broadcast</span>.</p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd>mat (Tensor): matrix to be multiplied
vec (Tensor): vector to be multiplied
out (Tensor, optional): Output tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">vec</span><span class="p">)</span>
<span class="go">-2.0939</span>
<span class="go">-2.2950</span>
<span class="go">[torch.FloatTensor of size 2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.ne">
<code class="descclassname">syft.</code><code class="descname">ne</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.ne" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes <cite>tensor != other</cite> element-wise.</p>
<p>The second argument can be a number or a tensor whose shape is
<span class="xref std std-ref">broadcastable</span> with the first argument.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">input (Tensor): Tensor to compare
other (Tensor or float): Tensor or value to compare
out (Tensor, optional): Output tensor. Must be a <cite>ByteTensor</cite> or the same</p>
<blockquote class="last">
<div>type as <cite>tensor</cite>.</div></blockquote>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>Tensor: a <code class="docutils literal"><span class="pre">torch.ByteTensor</span></code> containing a 1 at each location where</dt>
<dd>comparison is true.</dd>
</dl>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]))</span>
<span class="go"> 0  1</span>
<span class="go"> 1  0</span>
<span class="go">[torch.ByteTensor of size 2x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.neg">
<code class="descclassname">syft.</code><code class="descname">neg</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.neg" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the negative of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<p><span class="math">\(out = -1 * input\)</span></p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.4430</span>
<span class="go"> 1.1690</span>
<span class="go">-0.8836</span>
<span class="go">-0.4565</span>
<span class="go"> 0.2968</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 0.4430</span>
<span class="go">-1.1690</span>
<span class="go"> 0.8836</span>
<span class="go"> 0.4565</span>
<span class="go">-0.2968</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.nonzero">
<code class="descclassname">syft.</code><code class="descname">nonzero</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; LongTensor<a class="headerlink" href="#syft.nonzero" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a tensor containing the indices of all non-zero elements of
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.  Each row in the result contains the indices of a non-zero
element in <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> has <cite>n</cite> dimensions, then the resulting indices Tensor
<code class="xref py py-attr docutils literal"><span class="pre">out</span></code> is of size <cite>z x n</cite>, where <cite>z</cite> is the total number of non-zero
elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (LongTensor, optional): The result <cite>Tensor</cite> containing indices</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>

<span class="go"> 0</span>
<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 4</span>
<span class="go">[torch.LongTensor of size 4x1]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
<span class="gp">... </span>                            <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
<span class="gp">... </span>                            <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
<span class="gp">... </span>                            <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span><span class="o">-</span><span class="mf">0.4</span><span class="p">]]))</span>

<span class="go"> 0  0</span>
<span class="go"> 1  1</span>
<span class="go"> 2  2</span>
<span class="go"> 3  3</span>
<span class="go">[torch.LongTensor of size 4x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.norm">
<code class="descclassname">syft.</code><code class="descname">norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.norm" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">norm</code><span class="sig-paren">(</span><em>input</em>, <em>p=2</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the p-norm of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
p (float, optional): the exponent value in the norm formulation</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.4376 -0.5328  0.9547</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">1.0338925067372466</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">norm</code><span class="sig-paren">(</span><em>input</em>, <em>p</em>, <em>dim</em>, <em>keepdim=False</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Returns the p-norm of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is <code class="docutils literal"><span class="pre">True</span></code>, the output Tensor is of the same size as
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where it is of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code>), resulting
in the output Tensor having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
p (float):  the exponent value in the norm formulation
dim (int): the dimension to reduce
keepdim (bool): whether the output Tensor has <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not
out (Tensor, optional): the result Tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.6891 -0.6662</span>
<span class="go"> 0.2697  0.7412</span>
<span class="go"> 0.5254 -0.7402</span>
<span class="go"> 0.5528 -0.2399</span>
<span class="go">[torch.FloatTensor of size 4x2]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="go"> 0.9585</span>
<span class="go"> 0.7888</span>
<span class="go"> 0.9077</span>
<span class="go"> 0.6026</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

<span class="go"> 2</span>
<span class="go"> 2</span>
<span class="go"> 2</span>
<span class="go"> 2</span>
<span class="go">[torch.FloatTensor of size 4x1]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.normal">
<code class="descclassname">syft.</code><code class="descname">normal</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.normal" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">normal</code><span class="sig-paren">(</span><em>means</em>, <em>std</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Returns a Tensor of random numbers drawn from separate normal distributions
who&#8217;s mean and standard deviation are given.</p>
<p>The <code class="xref py py-attr docutils literal"><span class="pre">means</span></code> is a Tensor with the mean of
each output element&#8217;s normal distribution</p>
<p>The <a class="reference internal" href="../index.html#syft.std" title="syft.std"><code class="xref py py-attr docutils literal"><span class="pre">std</span></code></a> is a Tensor with the standard deviation of
each output element&#8217;s normal distribution</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">means</span></code> and <a class="reference internal" href="../index.html#syft.std" title="syft.std"><code class="xref py py-attr docutils literal"><span class="pre">std</span></code></a> don&#8217;t need to match.
The total number of elements in each Tensor need to be the same.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">When the shapes do not match, the shape of <code class="xref py py-attr docutils literal"><span class="pre">means</span></code>
is used as the shape for the returned output Tensor</p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd>means (Tensor): the Tensor of per-element means
std (Tensor): the Tensor of per-element standard deviations
out (Tensor): the optional result Tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">means</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">))</span>

 <span class="mf">1.5104</span>
 <span class="mf">1.6955</span>
 <span class="mf">2.4895</span>
 <span class="mf">4.9185</span>
 <span class="mf">4.9895</span>
 <span class="mf">6.9155</span>
 <span class="mf">7.3683</span>
 <span class="mf">8.1836</span>
 <span class="mf">8.7164</span>
 <span class="mf">9.8916</span>
<span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">normal</code><span class="sig-paren">(</span><em>mean=0.0</em>, <em>std</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Similar to the function above, but the means are shared among all drawn
elements.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>means (float, optional): the mean for all distributions
std (Tensor): the Tensor of per-element standard deviations
out (Tensor): the optional result Tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="go">  0.5723</span>
<span class="go">  0.0871</span>
<span class="go"> -0.3783</span>
<span class="go"> -2.5689</span>
<span class="go"> 10.7893</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">normal</code><span class="sig-paren">(</span><em>means</em>, <em>std=1.0</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Similar to the function above, but the standard-deviations are shared among
all drawn elements.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>means (Tensor): the Tensor of per-element means
std (float, optional): the standard deviation for all distributions
out (Tensor): the optional result Tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">means</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="go"> 1.1681</span>
<span class="go"> 2.8884</span>
<span class="go"> 3.7718</span>
<span class="go"> 2.5616</span>
<span class="go"> 4.2500</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.numel">
<code class="descclassname">syft.</code><code class="descname">numel</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#syft.numel" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the total number of elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">numel</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">120</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">numel</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">16</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.ones">
<code class="descclassname">syft.</code><code class="descname">ones</code><span class="sig-paren">(</span><em>*sizes</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.ones" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a Tensor filled with the scalar value <cite>1</cite>, with the shape defined
by the varargs <code class="xref py py-attr docutils literal"><span class="pre">sizes</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>sizes (int...): a set of ints defining the shape of the output Tensor.
out (Tensor, optional): the result Tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="go"> 1  1  1</span>
<span class="go"> 1  1  1</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="go"> 1</span>
<span class="go"> 1</span>
<span class="go"> 1</span>
<span class="go"> 1</span>
<span class="go"> 1</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.ones_like">
<code class="descclassname">syft.</code><code class="descname">ones_like</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.ones_like" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a Tensor filled with the scalar value <cite>1</cite>, with the same size as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): The size of the input will determine the size of the output.
out (Tensor, optional): the result Tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

<span class="go"> 1  1  1</span>
<span class="go"> 1  1  1</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.orgqr">
<code class="descclassname">syft.</code><code class="descname">orgqr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.orgqr" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="syft.ormqr">
<code class="descclassname">syft.</code><code class="descname">ormqr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.ormqr" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="syft.potrf">
<code class="descclassname">syft.</code><code class="descname">potrf</code><span class="sig-paren">(</span><em>a</em>, <em>out=None</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.potrf" title="Permalink to this definition">¶</a></dt>
<dd><p>potrf(a, upper, out=None)</p>
<p>Computes the Cholesky decomposition of a positive semidefinite
matrix <code class="xref py py-attr docutils literal"><span class="pre">a</span></code>: returns matrix <cite>u</cite>
If <cite>upper</cite> is <code class="docutils literal"><span class="pre">True</span></code> or not provided, <cite>u</cite> is upper triangular
such that <span class="math">\(a = u^T u\)</span>.
If <cite>upper</cite> is <code class="docutils literal"><span class="pre">False</span></code>, <cite>u</cite> is lower triangular
such that <span class="math">\(a = u u^T\)</span>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>a (Tensor): the input 2D <cite>Tensor</cite>, a symmetric positive semidefinite matrix
upper (bool, optional): Return upper (default) or lower triangular matrix
out (Tensor, optional): A Tensor for u</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">t</span><span class="p">())</span> <span class="c1"># make symmetric positive definite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">potrf</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 2.3563  3.2318 -0.9406</span>
<span class="go"> 3.2318  4.9557 -2.1618</span>
<span class="go">-0.9406 -2.1618  2.2443</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span>

<span class="go"> 1.5350  2.1054 -0.6127</span>
<span class="go"> 0.0000  0.7233 -1.2053</span>
<span class="go"> 0.0000  0.0000  0.6451</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">t</span><span class="p">(),</span><span class="n">u</span><span class="p">)</span>

<span class="go"> 2.3563  3.2318 -0.9406</span>
<span class="go"> 3.2318  4.9557 -2.1618</span>
<span class="go">-0.9406 -2.1618  2.2443</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.potri">
<code class="descclassname">syft.</code><code class="descname">potri</code><span class="sig-paren">(</span><em>u</em>, <em>out=None</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.potri" title="Permalink to this definition">¶</a></dt>
<dd><p>potri(u, upper, out=None)</p>
<p>Computes the inverse of a positive semidefinite matrix given its
Cholesky factor <code class="xref py py-attr docutils literal"><span class="pre">u</span></code>: returns matrix <cite>inv</cite>
If <cite>upper</cite> is <code class="docutils literal"><span class="pre">True</span></code> or not provided, <cite>u</cite> is upper triangular
such that <span class="math">\(inv = (u^T u)^{-1}\)</span>.
If <cite>upper</cite> is <code class="docutils literal"><span class="pre">False</span></code>, <cite>u</cite> is lower triangular
such that <span class="math">\(inv = (u u^T)^{-1}\)</span>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first docutils">
<dt>u (Tensor): the input 2D <cite>Tensor</cite>, a upper or lower triangular</dt>
<dd>Cholesky factor</dd>
</dl>
<p class="last">upper (bool, optional): Flag if upper (default) or lower triangular matrix
out (Tensor, optional): A Tensor for inv</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">t</span><span class="p">())</span> <span class="c1"># make symmetric positive definite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">potrf</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 2.3563  3.2318 -0.9406</span>
<span class="go"> 3.2318  4.9557 -2.1618</span>
<span class="go">-0.9406 -2.1618  2.2443</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">potri</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>

<span class="go"> 12.5724 -10.1765  -4.5333</span>
<span class="go">-10.1765   8.5852   4.0047</span>
<span class="go"> -4.5333   4.0047   2.4031</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">inverse</span><span class="p">()</span>

<span class="go"> 12.5723 -10.1765  -4.5333</span>
<span class="go">-10.1765   8.5852   4.0047</span>
<span class="go"> -4.5333   4.0047   2.4031</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.potrs">
<code class="descclassname">syft.</code><code class="descname">potrs</code><span class="sig-paren">(</span><em>b</em>, <em>u</em>, <em>out=None</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.potrs" title="Permalink to this definition">¶</a></dt>
<dd><p>potrs(b, u, upper, out=None)</p>
<p>Solves a linear system of equations with a positive semidefinite
matrix to be inverted given its given a Cholesky factor
matrix <code class="xref py py-attr docutils literal"><span class="pre">u</span></code>: returns matrix <cite>c</cite>
If <cite>upper</cite> is <code class="docutils literal"><span class="pre">True</span></code> or not provided, <cite>u</cite> is and upper triangular
such that <span class="math">\(c = (u^T u)^{-1} b\)</span>.
If <cite>upper</cite> is <code class="docutils literal"><span class="pre">False</span></code>, <cite>u</cite> is and lower triangular
such that <span class="math">\(c = (u u^T)^{-1} b\)</span>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><cite>b</cite> is always a 2D <cite>Tensor</cite>, use <cite>b.unsqueeze(1)</cite> to convert a vector.</p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">b (Tensor): the right hand side 2D <cite>Tensor</cite>
u (Tensor): the input 2D <cite>Tensor</cite>, a upper or lower triangular</p>
<blockquote>
<div>Cholesky factor</div></blockquote>
<p class="last">upper (bool, optional): Return upper (default) or lower triangular matrix
out (Tensor, optional): A Tensor for c</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">t</span><span class="p">())</span> <span class="c1"># make symmetric positive definite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">potrf</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 2.3563  3.2318 -0.9406</span>
<span class="go"> 3.2318  4.9557 -2.1618</span>
<span class="go">-0.9406 -2.1618  2.2443</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>

<span class="go">-0.3119 -1.8224</span>
<span class="go">-0.2798  0.1789</span>
<span class="go">-0.3735  1.7451</span>
<span class="go">[torch.FloatTensor of size 3x2]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">potrs</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="n">u</span><span class="p">)</span>

<span class="go"> 0.6187 -32.6438</span>
<span class="go">-0.7234  27.0703</span>
<span class="go">-0.6039  13.1717</span>
<span class="go">[torch.FloatTensor of size 3x2]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">inverse</span><span class="p">(),</span><span class="n">b</span><span class="p">)</span>

<span class="go"> 0.6187 -32.6436</span>
<span class="go">-0.7234  27.0702</span>
<span class="go">-0.6039  13.1717</span>
<span class="go">[torch.FloatTensor of size 3x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.pow">
<code class="descclassname">syft.</code><code class="descname">pow</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.pow" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">pow</code><span class="sig-paren">(</span><em>input</em>, <em>exponent</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Takes the power of each element in <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> with <code class="xref py py-attr docutils literal"><span class="pre">exponent</span></code> and
returns a Tensor with the result.</p>
<p><code class="xref py py-attr docutils literal"><span class="pre">exponent</span></code> can be either a single <code class="docutils literal"><span class="pre">float</span></code> number or a <code class="docutils literal"><span class="pre">Tensor</span></code>
with the same number of elements as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<p>When <code class="xref py py-attr docutils literal"><span class="pre">exponent</span></code> is a scalar value, the operation applied is:</p>
<p><span class="math">\(out_i = x_i ^ {exponent}\)</span></p>
<p>When <code class="xref py py-attr docutils literal"><span class="pre">exponent</span></code> is a Tensor, the operation applied is:</p>
<p><span class="math">\(out_i = x_i ^ {exponent_i}\)</span></p>
<p>When <code class="xref py py-attr docutils literal"><span class="pre">exponent</span></code> is a Tensor, the shapes of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>
and <code class="xref py py-attr docutils literal"><span class="pre">exponent</span></code> must be <span class="xref std std-ref">broadcastable</span>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
exponent (float or Tensor): the exponent value
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.5274</span>
<span class="go">-0.8232</span>
<span class="go">-2.1128</span>
<span class="go"> 1.7558</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="go"> 0.2781</span>
<span class="go"> 0.6776</span>
<span class="go"> 4.4640</span>
<span class="go"> 3.0829</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">exp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">exp</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">exp</span><span class="p">)</span>

<span class="go">   1</span>
<span class="go">   4</span>
<span class="go">  27</span>
<span class="go"> 256</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">pow</code><span class="sig-paren">(</span><em>base</em>, <em>input</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p><code class="xref py py-attr docutils literal"><span class="pre">base</span></code> is a scalar <code class="docutils literal"><span class="pre">float</span></code> value, and <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is a Tensor.
The returned Tensor <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> is of the same shape as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code></p>
<p>The operation applied is:</p>
<p><span class="math">\(out_i = base ^ {input_i}\)</span></p>
<dl class="docutils">
<dt>Args:</dt>
<dd>base (float): the scalar base value for the power operation
input (Tensor): the exponent <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">exp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">base</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">exp</span><span class="p">)</span>

<span class="go">  2</span>
<span class="go">  4</span>
<span class="go">  8</span>
<span class="go"> 16</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.prod">
<code class="descclassname">syft.</code><code class="descname">prod</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.prod" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">prod</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the product of all elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.6170  0.3546  0.0253</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">0.005537458061418483</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">prod</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>keepdim=False</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Returns the product of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is <code class="docutils literal"><span class="pre">True</span></code>, the output Tensor is of the same size as
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where it is of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code>), resulting
in the output Tensor having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
dim (int): the dimension to reduce
keepdim (bool): whether the output Tensor has <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not
out (Tensor, optional): the result Tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.1598 -0.6884</span>
<span class="go">-0.1831 -0.4412</span>
<span class="go">-0.9925 -0.6244</span>
<span class="go">-0.2416 -0.8080</span>
<span class="go">[torch.FloatTensor of size 4x2]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="go">-0.1100</span>
<span class="go"> 0.0808</span>
<span class="go"> 0.6197</span>
<span class="go"> 0.1952</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.pstrf">
<code class="descclassname">syft.</code><code class="descname">pstrf</code><span class="sig-paren">(</span><em>a</em>, <em>out=None</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.pstrf" title="Permalink to this definition">¶</a></dt>
<dd><p>pstrf(a, upper, out=None)</p>
<p>Computes the pivoted Cholesky decomposition of a positive semidefinite
matrix <code class="xref py py-attr docutils literal"><span class="pre">a</span></code>: returns matrices <cite>u</cite> and <cite>piv</cite>.
If <cite>upper</cite> is <code class="docutils literal"><span class="pre">True</span></code> or not provided, <cite>u</cite> is and upper triangular
such that <span class="math">\(a = p^T u^T u p\)</span>, with <cite>p</cite> the permutation given by <cite>piv</cite>.
If <cite>upper</cite> is <code class="docutils literal"><span class="pre">False</span></code>, <cite>u</cite> is and lower triangular
such that <span class="math">\(a = p^T u u^T p\)</span>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>a (Tensor): the input 2D <cite>Tensor</cite>
upper (bool, optional): Return upper (default) or lower triangular matrix
out (tuple, optional): A tuple of u and piv Tensors</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">t</span><span class="p">())</span> <span class="c1"># make symmetric positive definite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 5.4417 -2.5280  1.3643</span>
<span class="go">-2.5280  2.9689 -2.1368</span>
<span class="go"> 1.3643 -2.1368  4.6116</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span><span class="p">,</span><span class="n">piv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pstrf</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span>

<span class="go"> 2.3328  0.5848 -1.0837</span>
<span class="go"> 0.0000  2.0663 -0.7274</span>
<span class="go"> 0.0000  0.0000  1.1249</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">piv</span>

<span class="go"> 0</span>
<span class="go"> 2</span>
<span class="go"> 1</span>
<span class="go">[torch.IntTensor of size 3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">piv</span><span class="o">.</span><span class="n">long</span><span class="p">())</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">piv</span><span class="o">.</span><span class="n">long</span><span class="p">())</span><span class="o">.</span><span class="n">t</span><span class="p">()</span> <span class="c1"># make pivot permutation</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">t</span><span class="p">(),</span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">t</span><span class="p">(),</span><span class="n">u</span><span class="p">)),</span><span class="n">p</span><span class="p">)</span> <span class="c1"># reconstruct</span>

<span class="go"> 5.4417  1.3643 -2.5280</span>
<span class="go"> 1.3643  4.6116 -2.1368</span>
<span class="go">-2.5280 -2.1368  2.9689</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.qr">
<code class="descclassname">syft.</code><code class="descname">qr</code><span class="sig-paren">(</span><em>input</em>, <em>out=None) -&gt; (Tensor</em>, <em>Tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.qr" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the QR decomposition of a matrix <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>: returns matrices
<cite>q</cite> and <cite>r</cite> such that <span class="math">\(x = q * r\)</span>, with <cite>q</cite> being an orthogonal matrix
and <cite>r</cite> being an upper triangular matrix.</p>
<p>This returns the thin (reduced) QR factorization.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">precision may be lost if the magnitudes of the elements of <cite>input</cite>
are large</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">while it should always give you a valid decomposition, it may not
give you the same one across platforms - it will depend on your
LAPACK implementation.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Irrespective of the original strides, the returned matrix <cite>q</cite> will be
transposed, i.e. with strides <cite>(1, m)</cite> instead of <cite>(m, 1)</cite>.</p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input 2D <cite>Tensor</cite>
out (tuple, optional): A tuple of Q and R Tensors</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">12</span><span class="p">,</span> <span class="o">-</span><span class="mi">51</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">167</span><span class="p">,</span> <span class="o">-</span><span class="mi">68</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="o">-</span><span class="mi">41</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">q</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">q</span>

<span class="go">-0.8571  0.3943  0.3314</span>
<span class="go">-0.4286 -0.9029 -0.0343</span>
<span class="go"> 0.2857 -0.1714  0.9429</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span>

<span class="go"> -14.0000  -21.0000   14.0000</span>
<span class="go">   0.0000 -175.0000   70.0000</span>
<span class="go">   0.0000    0.0000  -35.0000</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>

<span class="go">  12  -51    4</span>
<span class="go">   6  167  -68</span>
<span class="go">  -4   24  -41</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">t</span><span class="p">(),</span> <span class="n">q</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>

<span class="go"> 1 -0  0</span>
<span class="go">-0  1  0</span>
<span class="go"> 0  0  1</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.rand">
<code class="descclassname">syft.</code><code class="descname">rand</code><span class="sig-paren">(</span><em>*sizes</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.rand" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a Tensor filled with random numbers from a uniform distribution
on the interval <span class="math">\([0, 1)\)</span></p>
<p>The shape of the Tensor is defined by the varargs <code class="xref py py-attr docutils literal"><span class="pre">sizes</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>sizes (int...): a set of ints defining the shape of the output Tensor.
out (Tensor, optional): the result Tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="go"> 0.9193</span>
<span class="go"> 0.3347</span>
<span class="go"> 0.3232</span>
<span class="go"> 0.7715</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="go"> 0.5010  0.5140  0.0719</span>
<span class="go"> 0.1435  0.5636  0.0538</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.randn">
<code class="descclassname">syft.</code><code class="descname">randn</code><span class="sig-paren">(</span><em>*sizes</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.randn" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a Tensor filled with random numbers from a normal distribution
with zero mean and variance of one.</p>
<p>The shape of the Tensor is defined by the varargs <code class="xref py py-attr docutils literal"><span class="pre">sizes</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>sizes (int...): a set of ints defining the shape of the output Tensor.
out (Tensor, optional): the result Tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="go">-0.1145</span>
<span class="go"> 0.0094</span>
<span class="go">-1.1717</span>
<span class="go"> 0.9846</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="go"> 1.4339  0.3351 -1.0999</span>
<span class="go"> 1.5458 -0.9643 -0.3558</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.randperm">
<code class="descclassname">syft.</code><code class="descname">randperm</code><span class="sig-paren">(</span><em>n</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; LongTensor<a class="headerlink" href="#syft.randperm" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a random permutation of integers from <code class="docutils literal"><span class="pre">0</span></code> to <code class="docutils literal"><span class="pre">n</span> <span class="pre">-</span> <span class="pre">1</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>n (int): the upper bound (exclusive)</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="go"> 2</span>
<span class="go"> 1</span>
<span class="go"> 3</span>
<span class="go"> 0</span>
<span class="go">[torch.LongTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.range">
<code class="descclassname">syft.</code><code class="descname">range</code><span class="sig-paren">(</span><em>start</em>, <em>end</em>, <em>step=1</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.range" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a 1D Tensor of size <span class="math">\(floor((end - start) / step) + 1\)</span> with values
from <code class="xref py py-attr docutils literal"><span class="pre">start</span></code> to <code class="xref py py-attr docutils literal"><span class="pre">end</span></code> with step <code class="xref py py-attr docutils literal"><span class="pre">step</span></code>. Step is the gap
between two values in the tensor. <span class="math">\(x_{i+1} = x_i + step\)</span></p>
<dl class="docutils">
<dt>Warning:</dt>
<dd>This function is deprecated in favor of <code class="xref py py-func docutils literal"><span class="pre">torch.arange()</span></code>.</dd>
<dt>Args:</dt>
<dd>start (float): The starting value for the set of points
end (float): The ending value for the set of points
step (float): The gap between each pair of adjacent points
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="go"> 1.0000</span>
<span class="go"> 1.5000</span>
<span class="go"> 2.0000</span>
<span class="go"> 2.5000</span>
<span class="go"> 3.0000</span>
<span class="go"> 3.5000</span>
<span class="go"> 4.0000</span>
<span class="go">[torch.FloatTensor of size 7]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.reciprocal">
<code class="descclassname">syft.</code><code class="descname">reciprocal</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.reciprocal" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the reciprocal of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>,
i.e. <span class="math">\(1.0 / x\)</span></p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">reciprocal</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 0.7210</span>
<span class="go"> 2.5565</span>
<span class="go">-1.1583</span>
<span class="go">-1.8289</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.remainder">
<code class="descclassname">syft.</code><code class="descname">remainder</code><span class="sig-paren">(</span><em>input</em>, <em>divisor</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.remainder" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the element-wise remainder of division.</p>
<p>The divisor and dividend may contain both for integer and floating point
numbers. The remainder has the same sign as the divisor.</p>
<p>When <code class="xref py py-attr docutils literal"><span class="pre">divisor</span></code> is a Tensor, the shapes of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and
<code class="xref py py-attr docutils literal"><span class="pre">divisor</span></code> must be <span class="xref std std-ref">broadcastable</span>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">input (Tensor): The dividend
divisor (Tensor or float): The divisor. This may be either a number or a</p>
<blockquote>
<div>tensor of the same shape as the dividend.</div></blockquote>
<p class="last">out (Tensor, optional): Output tensor</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">remainder</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">torch.FloatTensor([1, 0, 1, 1, 0, 1])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">remainder</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]),</span> <span class="mf">1.5</span><span class="p">)</span>
<span class="go">torch.FloatTensor([1.0, 0.5, 0.0, 1.0, 0.5])</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><code class="xref py py-func docutils literal"><span class="pre">torch.fmod()</span></code>, which computes the element-wise remainder of
division equivalently to the C library function <code class="docutils literal"><span class="pre">fmod()</span></code></p>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.renorm">
<code class="descclassname">syft.</code><code class="descname">renorm</code><span class="sig-paren">(</span><em>input</em>, <em>p</em>, <em>dim</em>, <em>maxnorm</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.renorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a Tensor where each sub-tensor of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> along dimension
<code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is normalized such that the <cite>p</cite>-norm of the sub-tensor is lower
than the value <code class="xref py py-attr docutils literal"><span class="pre">maxnorm</span></code></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If the norm of a row is lower than <cite>maxnorm</cite>, the row is unchanged</p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): The input Tensor
p (float): The power for the norm computation
dim (int): The dimension to slice over to get the sub-tensors
maxnorm (float): The maximum norm to keep each sub-tensor under
out (Tensor, optional): Output tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 1  1  1</span>
<span class="go"> 2  2  2</span>
<span class="go"> 3  3  3</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">renorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="go"> 1.0000  1.0000  1.0000</span>
<span class="go"> 1.6667  1.6667  1.6667</span>
<span class="go"> 1.6667  1.6667  1.6667</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.round">
<code class="descclassname">syft.</code><code class="descname">round</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.round" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with each of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> rounded
to the closest integer.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.2290</span>
<span class="go"> 1.3409</span>
<span class="go">-0.5662</span>
<span class="go">-0.0899</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 1</span>
<span class="go"> 1</span>
<span class="go">-1</span>
<span class="go">-0</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.rsqrt">
<code class="descclassname">syft.</code><code class="descname">rsqrt</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.rsqrt" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the reciprocal of the square-root of each of
the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.2290</span>
<span class="go"> 1.3409</span>
<span class="go">-0.5662</span>
<span class="go">-0.0899</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 0.9020</span>
<span class="go"> 0.8636</span>
<span class="go">    nan</span>
<span class="go">    nan</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.saddmm">
<code class="descclassname">syft.</code><code class="descname">saddmm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.saddmm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="syft.set_num_threads">
<code class="descclassname">syft.</code><code class="descname">set_num_threads</code><span class="sig-paren">(</span><em>int</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.set_num_threads" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the number of OpenMP threads used for parallelizing CPU operations</p>
</dd></dl>

<dl class="function">
<dt id="syft.sigmoid">
<code class="descclassname">syft.</code><code class="descname">sigmoid</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.sigmoid" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the sigmoid of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.4972</span>
<span class="go"> 1.3512</span>
<span class="go"> 0.1056</span>
<span class="go">-0.2650</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 0.3782</span>
<span class="go"> 0.7943</span>
<span class="go"> 0.5264</span>
<span class="go"> 0.4341</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.sign">
<code class="descclassname">syft.</code><code class="descname">sign</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.sign" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the sign of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go">-1</span>
<span class="go"> 1</span>
<span class="go"> 1</span>
<span class="go"> 1</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.sin">
<code class="descclassname">syft.</code><code class="descname">sin</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.sin" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the sine of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">-0.5944</span>
<span class="go"> 0.2684</span>
<span class="go"> 0.4322</span>
<span class="go"> 0.9667</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.sinh">
<code class="descclassname">syft.</code><code class="descname">sinh</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.sinh" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the hyperbolic sine of the elements of
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">sinh</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">-0.6804</span>
<span class="go"> 0.2751</span>
<span class="go"> 0.4619</span>
<span class="go"> 1.7225</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.smm">
<code class="descclassname">syft.</code><code class="descname">smm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.smm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="syft.sort">
<code class="descclassname">syft.</code><code class="descname">sort</code><span class="sig-paren">(</span><em>input</em>, <em>dim=None</em>, <em>descending=False</em>, <em>out=None) -&gt; (Tensor</em>, <em>LongTensor</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.sort" title="Permalink to this definition">¶</a></dt>
<dd><p>Sorts the elements of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor along a given dimension
in ascending order by value.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is not given, the last dimension of the <cite>input</cite> is chosen.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">descending</span></code> is <code class="docutils literal"><span class="pre">True</span></code> then the elements are sorted in descending
order by value.</p>
<p>A tuple of (sorted_tensor, sorted_indices) is returned, where the
sorted_indices are the indices of the elements in the original <cite>input</cite> Tensor.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">input (Tensor): the input <cite>Tensor</cite>
dim (int, optional): The dimension to sort along
descending (bool, optional): Controls the sorting order</p>
<blockquote>
<div>(ascending or descending)</div></blockquote>
<dl class="last docutils">
<dt>out (tuple, optional): The output tuple of (Tensor, LongTensor)</dt>
<dd>can be optionally given to be used as output buffers</dd>
</dl>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span>

<span class="go">-1.6747  0.0610  0.1190  1.4137</span>
<span class="go">-1.4782  0.7159  1.0341  1.3678</span>
<span class="go">-0.3324 -0.0782  0.3518  0.4763</span>
<span class="go">[torch.FloatTensor of size 3x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span>

<span class="go"> 0  1  3  2</span>
<span class="go"> 2  1  0  3</span>
<span class="go"> 3  1  0  2</span>
<span class="go">[torch.LongTensor of size 3x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span>

<span class="go">-1.6747 -0.0782 -1.4782 -0.3324</span>
<span class="go"> 0.3518  0.0610  0.4763  0.1190</span>
<span class="go"> 1.0341  0.7159  1.4137  1.3678</span>
<span class="go">[torch.FloatTensor of size 3x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span>

<span class="go"> 0  2  1  2</span>
<span class="go"> 2  0  2  0</span>
<span class="go"> 1  1  0  1</span>
<span class="go">[torch.LongTensor of size 3x4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.sqrt">
<code class="descclassname">syft.</code><code class="descname">sqrt</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.sqrt" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the square-root of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.2290</span>
<span class="go"> 1.3409</span>
<span class="go">-0.5662</span>
<span class="go">-0.0899</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 1.1086</span>
<span class="go"> 1.1580</span>
<span class="go">    nan</span>
<span class="go">    nan</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.squeeze">
<code class="descclassname">syft.</code><code class="descname">squeeze</code><span class="sig-paren">(</span><em>input</em>, <em>dim=None</em>, <em>out=None</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.squeeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a <cite>Tensor</cite> with all the dimensions of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> of size <cite>1</cite> removed.</p>
<p>If <cite>input</cite> is of shape: <span class="math">\((A x 1 x B x C x 1 x D)\)</span> then the <cite>out</cite> Tensor
will be of shape: <span class="math">\((A x B x C x D)\)</span></p>
<p>When <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is given, a squeeze operation is done only in the given
dimension. If <cite>input</cite> is of shape: <span class="math">\((A x 1 x B)\)</span>, <cite>squeeze(input, 0)</cite>
leaves the Tensor unchanged, but <cite>squeeze(input, 1)</cite> will squeeze the tensor
to the shape <span class="math">\((A x B)\)</span>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">As an exception to the above, a 1-dimensional tensor of size 1 will
not have its dimensions changed.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The returned Tensor shares the storage with the input Tensor,
so changing the contents of one will change the contents of the other.</p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">input (Tensor): the input <cite>Tensor</cite>
dim (int, optional): if given, the input will be squeezed only in</p>
<blockquote>
<div>this dimension</div></blockquote>
<p class="last">out (Tensor, optional): The result <cite>Tensor</cite></p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">(2L, 1L, 2L, 1L, 2L)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">(2L, 2L, 2L)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">(2L, 1L, 2L, 1L, 2L)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">(2L, 2L, 1L, 2L)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.std">
<code class="descclassname">syft.</code><code class="descname">std</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.std" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">std</code><span class="sig-paren">(</span><em>input</em>, <em>unbiased=True</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the standard-deviation of all elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">unbiased</span></code> is <code class="docutils literal"><span class="pre">False</span></code>, then the standard-deviation will be calculated via
the biased estimator. Otherwise, Bessel&#8217;s correction will be used.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
unbiased (bool): whether to use the unbiased estimation or not</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-1.3063  1.4182 -0.3061</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">1.3782334731508061</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">std</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>keepdim=False</em>, <em>unbiased=True</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Returns the standard-deviation of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the
given dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is <code class="docutils literal"><span class="pre">True</span></code>, the output Tensor is of the same size as
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where it is of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code>), resulting
in the output Tensor having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">unbiased</span></code> is <code class="docutils literal"><span class="pre">False</span></code>, then the standard-deviation will be calculated via
the biased estimator. Otherwise, Bessel&#8217;s correction will be used.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
dim (int): the dimension to reduce
keepdim (bool): whether the output Tensor has <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not
unbiased (bool): whether to use the unbiased estimation or not
out (Tensor, optional): the result Tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.1889 -2.4856  0.0043  1.8169</span>
<span class="go">-0.7701 -0.4682 -2.2410  0.4098</span>
<span class="go"> 0.1919 -1.1856 -1.0361  0.9085</span>
<span class="go"> 0.0173  1.0662  0.2143 -0.5576</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="go"> 1.7756</span>
<span class="go"> 1.1025</span>
<span class="go"> 1.0045</span>
<span class="go"> 0.6725</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.sum">
<code class="descclassname">syft.</code><code class="descname">sum</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.sum" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">sum</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the sum of all elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.6170  0.3546  0.0253</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">0.9969287421554327</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">sum</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>keepdim=False</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Returns the sum of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is <code class="docutils literal"><span class="pre">True</span></code>, the output Tensor is of the same size
as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where it is of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code>), resulting in
the output Tensor having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
dim (int): the dimension to reduce
keepdim (bool): whether the output Tensor has <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not
out (Tensor, optional): the result Tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.4640  0.0609  0.1122  0.4784</span>
<span class="go">-1.3063  1.6443  0.4714 -0.7396</span>
<span class="go">-1.3561 -0.1959  1.0609 -1.9855</span>
<span class="go"> 2.6833  0.5746 -0.5709 -0.4430</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="go"> 0.1874</span>
<span class="go"> 0.0698</span>
<span class="go">-2.4767</span>
<span class="go"> 2.2440</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.svd">
<code class="descclassname">syft.</code><code class="descname">svd</code><span class="sig-paren">(</span><em>input</em>, <em>some=True</em>, <em>out=None) -&gt; (Tensor</em>, <em>Tensor</em>, <em>Tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.svd" title="Permalink to this definition">¶</a></dt>
<dd><p><cite>U, S, V = torch.svd(A)</cite> returns the singular value decomposition of a
real matrix <cite>A</cite> of size <cite>(n x m)</cite> such that <span class="math">\(A = USV'*\)</span>.</p>
<p><cite>U</cite> is of shape <cite>n x n</cite></p>
<p><cite>S</cite> is of shape <cite>n x m</cite></p>
<p><cite>V</cite> is of shape <cite>m x m</cite>.</p>
<p><code class="xref py py-attr docutils literal"><span class="pre">some</span></code> represents the number of singular values to be computed.
If <cite>some=True</cite>, it computes some and <cite>some=False</cite> computes all.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Irrespective of the original strides, the returned matrix <cite>U</cite>
will be transposed, i.e. with strides <cite>(1, n)</cite> instead of <cite>(n, 1)</cite>.</p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input 2D Tensor
some (bool, optional): controls the number of singular values to be computed
out (tuple, optional): the result tuple</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">8.79</span><span class="p">,</span>  <span class="mf">6.11</span><span class="p">,</span> <span class="o">-</span><span class="mf">9.15</span><span class="p">,</span>  <span class="mf">9.57</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.49</span><span class="p">,</span>  <span class="mf">9.84</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mf">9.93</span><span class="p">,</span>  <span class="mf">6.91</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.93</span><span class="p">,</span>  <span class="mf">1.64</span><span class="p">,</span>  <span class="mf">4.02</span><span class="p">,</span>  <span class="mf">0.15</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mf">9.83</span><span class="p">,</span>  <span class="mf">5.04</span><span class="p">,</span>  <span class="mf">4.86</span><span class="p">,</span>  <span class="mf">8.83</span><span class="p">,</span>  <span class="mf">9.80</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.99</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mf">5.45</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.27</span><span class="p">,</span>  <span class="mf">4.85</span><span class="p">,</span>  <span class="mf">0.74</span><span class="p">,</span> <span class="mf">10.00</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.02</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mf">3.16</span><span class="p">,</span>  <span class="mf">7.98</span><span class="p">,</span>  <span class="mf">3.01</span><span class="p">,</span>  <span class="mf">5.80</span><span class="p">,</span>  <span class="mf">4.27</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.31</span><span class="p">]])</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">  8.7900   9.9300   9.8300   5.4500   3.1600</span>
<span class="go">  6.1100   6.9100   5.0400  -0.2700   7.9800</span>
<span class="go"> -9.1500  -7.9300   4.8600   4.8500   3.0100</span>
<span class="go">  9.5700   1.6400   8.8300   0.7400   5.8000</span>
<span class="go"> -3.4900   4.0200   9.8000  10.0000   4.2700</span>
<span class="go">  9.8400   0.1500  -8.9900  -6.0200  -5.3100</span>
<span class="go">[torch.FloatTensor of size 6x5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span>

<span class="go">-0.5911  0.2632  0.3554  0.3143  0.2299</span>
<span class="go">-0.3976  0.2438 -0.2224 -0.7535 -0.3636</span>
<span class="go">-0.0335 -0.6003 -0.4508  0.2334 -0.3055</span>
<span class="go">-0.4297  0.2362 -0.6859  0.3319  0.1649</span>
<span class="go">-0.4697 -0.3509  0.3874  0.1587 -0.5183</span>
<span class="go"> 0.2934  0.5763 -0.0209  0.3791 -0.6526</span>
<span class="go">[torch.FloatTensor of size 6x5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span>

<span class="go"> 27.4687</span>
<span class="go"> 22.6432</span>
<span class="go">  8.5584</span>
<span class="go">  5.9857</span>
<span class="go">  2.0149</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span>

<span class="go">-0.2514  0.8148 -0.2606  0.3967 -0.2180</span>
<span class="go">-0.3968  0.3587  0.7008 -0.4507  0.1402</span>
<span class="go">-0.6922 -0.2489 -0.2208  0.2513  0.5891</span>
<span class="go">-0.3662 -0.3686  0.3859  0.4342 -0.6265</span>
<span class="go">-0.4076 -0.0980 -0.4932 -0.6227 -0.4396</span>
<span class="go">[torch.FloatTensor of size 5x5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="p">)),</span> <span class="n">v</span><span class="o">.</span><span class="n">t</span><span class="p">()))</span>
<span class="go">8.934150226306685e-06</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.symeig">
<code class="descclassname">syft.</code><code class="descname">symeig</code><span class="sig-paren">(</span><em>input</em>, <em>eigenvectors=False</em>, <em>upper=True</em>, <em>out=None) -&gt; (Tensor</em>, <em>Tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.symeig" title="Permalink to this definition">¶</a></dt>
<dd><p><cite>e, V = torch.symeig(input)</cite> returns eigenvalues and eigenvectors
of a symmetric real matrix <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<p><cite>input</cite> and <cite>V</cite> are <cite>m x m</cite> matrices and <cite>e</cite> is a <cite>m</cite> dimensional vector.</p>
<p>This function calculates all eigenvalues (and vectors) of <cite>input</cite>
such that <cite>input = V diag(e) V&#8217;</cite></p>
<p>The boolean argument <code class="xref py py-attr docutils literal"><span class="pre">eigenvectors</span></code> defines computation of
eigenvectors or eigenvalues only.</p>
<p>If it is <code class="docutils literal"><span class="pre">False</span></code>, only eigenvalues are computed. If it is <code class="docutils literal"><span class="pre">True</span></code>,
both eigenvalues and eigenvectors are computed.</p>
<p>Since the input matrix <cite>input</cite> is supposed to be symmetric,
only the upper triangular portion is used by default.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">upper</span></code> is <code class="docutils literal"><span class="pre">False</span></code>, then lower triangular portion is used.</p>
<p>Note: Irrespective of the original strides, the returned matrix <cite>V</cite> will
be transposed, i.e. with strides <cite>(1, m)</cite> instead of <cite>(m, 1)</cite>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">input (Tensor): the input symmetric matrix
eigenvectors(boolean, optional): controls whether eigenvectors have</p>
<blockquote>
<div>to be computed</div></blockquote>
<dl class="docutils">
<dt>upper(boolean, optional): controls whether to consider upper-triangular or</dt>
<dd>lower-triangular region</dd>
</dl>
<p class="last">out (tuple, optional): The result tuple of (Tensor, Tensor)</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span> <span class="mf">1.96</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="o">-</span><span class="mf">6.49</span><span class="p">,</span>  <span class="mf">3.80</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="o">-</span><span class="mf">0.47</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.39</span><span class="p">,</span>  <span class="mf">4.17</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="o">-</span><span class="mf">7.20</span><span class="p">,</span>  <span class="mf">1.50</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.51</span><span class="p">,</span>  <span class="mf">5.70</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="o">-</span><span class="mf">0.65</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.34</span><span class="p">,</span>  <span class="mf">2.67</span><span class="p">,</span>  <span class="mf">1.80</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.10</span><span class="p">]])</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">symeig</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">eigenvectors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span>

<span class="go">-11.0656</span>
<span class="go"> -6.2287</span>
<span class="go">  0.8640</span>
<span class="go">  8.8655</span>
<span class="go"> 16.0948</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span>

<span class="go">-0.2981 -0.6075  0.4026 -0.3745  0.4896</span>
<span class="go">-0.5078 -0.2880 -0.4066 -0.3572 -0.6053</span>
<span class="go">-0.0816 -0.3843 -0.6600  0.5008  0.3991</span>
<span class="go">-0.0036 -0.4467  0.4553  0.6204 -0.4564</span>
<span class="go">-0.8041  0.4480  0.1725  0.3108  0.1622</span>
<span class="go">[torch.FloatTensor of size 5x5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.t">
<code class="descclassname">syft.</code><code class="descname">t</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.t" title="Permalink to this definition">¶</a></dt>
<dd><p>Expects <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> to be a matrix (2D Tensor) and transposes
dimensions 0 and 1.</p>
<p>Can be seen as a short-hand function for <cite>transpose(input, 0, 1)</cite></p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 0.4834  0.6907  1.3417</span>
<span class="go">-0.1300  0.5295  0.2321</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="go"> 0.4834 -0.1300</span>
<span class="go"> 0.6907  0.5295</span>
<span class="go"> 1.3417  0.2321</span>
<span class="go">[torch.FloatTensor of size 3x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.take">
<code class="descclassname">syft.</code><code class="descname">take</code><span class="sig-paren">(</span><em>input</em>, <em>indices</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.take" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> at the given indices.
The input tensor is treated as if it were viewed as a 1D tensor. The result
takes the same shape as the indices.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
indices (LongTensor): the indices into <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">src</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
<span class="gp">... </span>                    <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">]))</span>
<span class="go"> 4</span>
<span class="go"> 5</span>
<span class="go"> 8</span>
<span class="go">[torch.FloatTensor of size 3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.tan">
<code class="descclassname">syft.</code><code class="descname">tan</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.tan" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the tangent of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tan</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">-0.7392</span>
<span class="go"> 0.2786</span>
<span class="go"> 0.4792</span>
<span class="go"> 3.7801</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.tanh">
<code class="descclassname">syft.</code><code class="descname">tanh</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.tanh" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the hyperbolic tangent of the elements
of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">-0.5625</span>
<span class="go"> 0.2653</span>
<span class="go"> 0.4193</span>
<span class="go"> 0.8648</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.topk">
<code class="descclassname">syft.</code><code class="descname">topk</code><span class="sig-paren">(</span><em>input</em>, <em>k</em>, <em>dim=None</em>, <em>largest=True</em>, <em>sorted=True</em>, <em>out=None) -&gt; (Tensor</em>, <em>LongTensor</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.topk" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the <code class="xref py py-attr docutils literal"><span class="pre">k</span></code> largest elements of the given <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor along
a given dimension.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is not given, the last dimension of the <cite>input</cite> is chosen.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">largest</span></code> is <code class="docutils literal"><span class="pre">False</span></code> then the <cite>k</cite> smallest elements are returned.</p>
<p>A tuple of <cite>(values, indices)</cite> is returned, where the <cite>indices</cite> are the indices
of the elements in the original <cite>input</cite> Tensor.</p>
<p>The boolean option <code class="xref py py-attr docutils literal"><span class="pre">sorted</span></code> if <code class="docutils literal"><span class="pre">True</span></code>, will make sure that the returned
<cite>k</cite> elements are themselves sorted</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">input (Tensor): the input <cite>Tensor</cite>
k (int): the k in &#8220;top-k&#8221;
dim (int, optional): The dimension to sort along
largest (bool, optional): Controls whether to return largest or</p>
<blockquote>
<div>smallest elements</div></blockquote>
<dl class="last docutils">
<dt>sorted (bool, optional): Controls whether to return the elements</dt>
<dd>in sorted order</dd>
<dt>out (tuple, optional): The output tuple of (Tensor, LongTensor)</dt>
<dd>can be optionally given to be used as output buffers</dd>
</dl>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go"> 5</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">(</span>
<span class="go"> 5</span>
<span class="go"> 4</span>
<span class="go"> 3</span>
<span class="go">[torch.FloatTensor of size 3]</span>
<span class="go">,</span>
<span class="go"> 4</span>
<span class="go"> 3</span>
<span class="go"> 2</span>
<span class="go">[torch.LongTensor of size 3]</span>
<span class="go">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">largest</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">(</span>
<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go">[torch.FloatTensor of size 3]</span>
<span class="go">,</span>
<span class="go"> 0</span>
<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go">[torch.LongTensor of size 3]</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.trace">
<code class="descclassname">syft.</code><code class="descname">trace</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#syft.trace" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the sum of the elements of the diagonal of the input 2D matrix.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 1  2  3</span>
<span class="go"> 4  5  6</span>
<span class="go"> 7  8  9</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">15.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.transpose">
<code class="descclassname">syft.</code><code class="descname">transpose</code><span class="sig-paren">(</span><em>input</em>, <em>dim0</em>, <em>dim1</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.transpose" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a <cite>Tensor</cite> that is a transposed version of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.
The given dimensions <code class="xref py py-attr docutils literal"><span class="pre">dim0</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">dim1</span></code> are swapped.</p>
<p>The resulting <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> Tensor shares it&#8217;s underlying storage with the
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor, so changing the content of one would change the content
of the other.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
dim0 (int): The first dimension to be transposed
dim1 (int): The second dimension to be transposed</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 0.5983 -0.0341  2.4918</span>
<span class="go"> 1.5981 -0.5265 -0.8735</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="go"> 0.5983  1.5981</span>
<span class="go">-0.0341 -0.5265</span>
<span class="go"> 2.4918 -0.8735</span>
<span class="go">[torch.FloatTensor of size 3x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.tril">
<code class="descclassname">syft.</code><code class="descname">tril</code><span class="sig-paren">(</span><em>input</em>, <em>diagonal=0</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.tril" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the lower triangular part of the matrix (2D Tensor) <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>,
the other elements of the result Tensor <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> are set to 0.</p>
<p>The lower triangular part of the matrix is defined as the elements on and
below the diagonal.</p>
<p>The argument <code class="xref py py-attr docutils literal"><span class="pre">diagonal</span></code> controls which diagonal to consider.</p>
<ul class="simple">
<li><code class="xref py py-attr docutils literal"><span class="pre">diagonal</span></code> = 0, is the main diagonal.</li>
<li><code class="xref py py-attr docutils literal"><span class="pre">diagonal</span></code> &gt; 0, is above the main diagonal.</li>
<li><code class="xref py py-attr docutils literal"><span class="pre">diagonal</span></code> &lt; 0, is below the main diagonal.</li>
</ul>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
diagonal (int, optional): the diagonal to consider
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3225  1.7304  1.4573</span>
<span class="go">-0.3052 -0.3111 -0.1809</span>
<span class="go"> 1.2469  0.0064 -1.6250</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 1.3225  0.0000  0.0000</span>
<span class="go">-0.3052 -0.3111  0.0000</span>
<span class="go"> 1.2469  0.0064 -1.6250</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="go"> 1.3225  1.7304  0.0000</span>
<span class="go">-0.3052 -0.3111 -0.1809</span>
<span class="go"> 1.2469  0.0064 -1.6250</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="go"> 0.0000  0.0000  0.0000</span>
<span class="go">-0.3052  0.0000  0.0000</span>
<span class="go"> 1.2469  0.0064  0.0000</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.triu">
<code class="descclassname">syft.</code><code class="descname">triu</code><span class="sig-paren">(</span><em>input</em>, <em>diagonal=0</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.triu" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the upper triangular part of the matrix (2D Tensor) <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>,
the other elements of the result Tensor <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> are set to 0.</p>
<p>The upper triangular part of the matrix is defined as the elements on and
above the diagonal.</p>
<p>The argument <code class="xref py py-attr docutils literal"><span class="pre">diagonal</span></code> controls which diagonal to consider.</p>
<ul class="simple">
<li><code class="xref py py-attr docutils literal"><span class="pre">diagonal</span></code> = 0, is the main diagonal.</li>
<li><code class="xref py py-attr docutils literal"><span class="pre">diagonal</span></code> &gt; 0, is above the main diagonal.</li>
<li><code class="xref py py-attr docutils literal"><span class="pre">diagonal</span></code> &lt; 0, is below the main diagonal.</li>
</ul>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
diagonal (int, optional): the diagonal to consider
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3225  1.7304  1.4573</span>
<span class="go">-0.3052 -0.3111 -0.1809</span>
<span class="go"> 1.2469  0.0064 -1.6250</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 1.3225  1.7304  1.4573</span>
<span class="go"> 0.0000 -0.3111 -0.1809</span>
<span class="go"> 0.0000  0.0000 -1.6250</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="go"> 0.0000  1.7304  1.4573</span>
<span class="go"> 0.0000  0.0000 -0.1809</span>
<span class="go"> 0.0000  0.0000  0.0000</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="go"> 1.3225  1.7304  1.4573</span>
<span class="go">-0.3052 -0.3111 -0.1809</span>
<span class="go"> 0.0000  0.0064 -1.6250</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.trtrs">
<code class="descclassname">syft.</code><code class="descname">trtrs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.trtrs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="syft.trunc">
<code class="descclassname">syft.</code><code class="descname">trunc</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.trunc" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the truncated integer values of
the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
out (Tensor, optional): The result <cite>Tensor</cite></dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.4972</span>
<span class="go"> 1.3512</span>
<span class="go"> 0.1056</span>
<span class="go">-0.2650</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">trunc</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go">-0</span>
<span class="go"> 1</span>
<span class="go"> 0</span>
<span class="go">-0</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.unsqueeze">
<code class="descclassname">syft.</code><code class="descname">unsqueeze</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>out=None</em><span class="sig-paren">)</span><a class="headerlink" href="#syft.unsqueeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new tensor with a dimension of size one inserted at the
specified position.</p>
<p>The returned tensor shares the same underlying data with this tensor.</p>
<p>A negative dim value can be used and will correspond to
<span class="math">\(dim + input.dim() + 1\)</span></p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
dim (int): The index at which to insert the singleton dimension
out (Tensor, optional): The result <cite>Tensor</cite></dd>
<dt>Example:</dt>
<dd><div class="first last highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="go"> 1  2  3  4</span>
<span class="go">[torch.FloatTensor of size 1x4]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go">[torch.FloatTensor of size 4x1]</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="syft.var">
<code class="descclassname">syft.</code><code class="descname">var</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.var" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">var</code><span class="sig-paren">(</span><em>input</em>, <em>unbiased=True</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the variance of all elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">unbiased</span></code> is <code class="docutils literal"><span class="pre">False</span></code>, then the variance will be calculated via the
biased estimator. Otherwise, Bessel&#8217;s correction will be used.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
unbiased (bool): whether to use the unbiased estimation or not</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-1.3063  1.4182 -0.3061</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">1.899527506513334</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">syft.</code><code class="descname">var</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>keepdim=False</em>, <em>unbiased=True</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Returns the variance of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is <code class="docutils literal"><span class="pre">True</span></code>, the output Tensors are of the same size
as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where they are of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code>), resulting in
the outputs Tensor having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">unbiased</span></code> is <code class="docutils literal"><span class="pre">False</span></code>, then the variance will be calculated via the
biased estimator. Otherwise, Bessel&#8217;s correction will be used.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): the input <cite>Tensor</cite>
dim (int): the dimension to reduce
keepdim (bool): whether the output Tensor has <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not
unbiased (bool): whether to use the unbiased estimation or not
out (Tensor, optional): the result Tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-1.2738 -0.3058  0.1230 -1.9615</span>
<span class="go"> 0.8771 -0.5430 -0.9233  0.9879</span>
<span class="go"> 1.4107  0.0317 -0.6823  0.2255</span>
<span class="go">-1.3854  0.4953 -0.2160  0.2435</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="go"> 0.8859</span>
<span class="go"> 0.9509</span>
<span class="go"> 0.7548</span>
<span class="go"> 0.6949</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.zero">
<code class="descclassname">syft.</code><code class="descname">zero</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#syft.zero" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="syft.zeros">
<code class="descclassname">syft.</code><code class="descname">zeros</code><span class="sig-paren">(</span><em>*sizes</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.zeros" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a Tensor filled with the scalar value <cite>0</cite>, with the shape defined
by the varargs <code class="xref py py-attr docutils literal"><span class="pre">sizes</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>sizes (int...): a set of ints defining the shape of the output Tensor.
out (Tensor, optional): the result Tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="go"> 0  0  0</span>
<span class="go"> 0  0  0</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="go"> 0</span>
<span class="go"> 0</span>
<span class="go"> 0</span>
<span class="go"> 0</span>
<span class="go"> 0</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="syft.zeros_like">
<code class="descclassname">syft.</code><code class="descname">zeros_like</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#syft.zeros_like" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a Tensor filled with the scalar value <cite>0</cite>, with the same size as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>input (Tensor): The size of the input will determine the size of the output.
out (Tensor, optional): the result Tensor</dd>
</dl>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

<span class="go"> 0  0  0</span>
<span class="go"> 0  0  0</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, OpenMined Contributors.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.1',
            LANGUAGE:'python',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>